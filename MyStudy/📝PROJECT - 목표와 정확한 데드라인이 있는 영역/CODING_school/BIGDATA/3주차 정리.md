
## 3. 빅데이터 활용 분야 모음

- IBM은 클라우드 플랫폼을 선정, IOT 기술을 통한 자동차 솔루션 개발
- 왓슨 플랫폼 : 금융, 방송, 의학, 교육, 쇼핑
- 관리 내용
    - 차량 데이터 관리 → IBM 클라우드인 Bluemix에서 IOT 플랫폼으로 관리
    - 실시간 차량 운행 분석 → 빅데이터 분석 서비스 제공
    - 운전자 행동 분석 →

- 빅데이터 활용 사례-GE
    - 가전제품 → 항공기엔진, 발전기 터빈 , 의료기기 생산 및 판매
    - 소프트웨어 기업으로 변신
    - 프레딕스 클라우드(predix Cloud) 출시 (세계 최초의 상업용 클라우도 솔루션)
    - 기업의 산업 자선 연결 - 기계/설비 → 데이터 분석/ 수집 → 시스템 자원 최적화

- 빅데이터 활용사례 -GE항공
    - GE제트 엔진이 부착된 센서 → 항공기 데이터 24시간 수집 및 분석
    - 조종사의 운항 습관, 기상상태, 연료 소모량 분석 + 효율적인 비행 운행 방법 제안, 고장위험 방지
    - 정비가 필요한 시기 예측 + 수집된 빅데이터로 새로운 가치 창출
    - 엔진 성능 향상과 비용 절감.

- 빅데이터 활용 사례 - GE파워
    - 발전용 가스터빈 생산 세계1위
    - GE Predix Cloud 기반의 GE 가스터빈 모니터링 & 진단센터 구축/운영
    - 축적된 데이터 분석 → 가장 효율적인 발전설비 운영 → 노하우 습득 → 발전 시설 최적화 + 문제 예방
    - 환경 아낌 ㄱㅇㄷ

- 빅데이터 활용사례 - 베스타스
    - 덴마크의 풍력터빈 생산 업체
    - 매우 비쌈
    - 최적의 위치 모형 개발 → 그리드로 나눔(1 * 1 km)
    - 기상 데이터 수집 및 페타 바이트 크기의 모델링
    - 데이터 특성
        - 대규모 데이터
        - 비구조화 데이터
        - 실시간 데이터
        - 기계가 생산하는 데이터
    - 적용효과
        - 실적 주가 크게 개선

- 빅데이터 활용사례 - 기상예측
    - 30pb의 신규데이터 관리, 위성 , 선박, 항공기 , 부표 → 35억개의 데이터 매일 수집
    - 기상청에 제공
    - 데이터 특성
        - 대규모 데이터
        - 비구조화 데이터
        - 실시간 데이터
        - 기계가 생산하는 데이터
    
- 빅데이터 활용 사례 - 볼보 자동차의 결함분석
- 활용내용
    - 운전과정의 자동차 내의 전자센서에 수집된 데이터를 분석 → 제품 개발 단계에서 알기 어려운 다양한 결함과 니즈 파악 → 빠른 대응
- 효과 분석
    - 사후 관리 비용 절감
    - 데이터 특성
        - 대규모 데이터
        - 비구조화 데이터
        - 실시간 데이터
        - 기계가 생산하는 데이터
        
- 빅데이터 활용 사례 - 보스톤시 스트리트 범프
    - 활용내용
        - Porthole(파손구멍) 감지 → 스마트폼 앱 개발을 하여 시민들에게 배포
        - 스마트폰의 GPS와 센서를 활용 → 자동차의 진동 감지
        도로관리국 도로정보 수집서버에 위치정보 실시간 전송
        - 수집된 데이터를 바탕으로 포트홀의 위치 추정 , 예상지점에 인력을 파견하여 도로 상태를 점검하고 유지 보수 실시.
    - 효과 분석
        - 신속한 도로 유지보수를 통한 비용절감 및 안전사고 예방에 기여
    - 데이터 특성
        - 대규모 데이터
        - 비구조화 데이터
        - 실시간 데이터
        - 기계가 생산하는 데이터
        - 소셜미디어 데이터

- 빅데이터 활용 사례 - Progressive 보험사의 사고 가능성 예측 모델
- 활용내용
- 계약자의 차에 운행기록 장치를 장착해 주행거리 , 주행속도, 급 코너링, 급 가속, 주행 시간대, 주행도로 종류 등 전반적인 고객의 운전행태에 대한 데이터 수집
- 사고 가능성 예측 보험료를 산정
- 데이터 특성
    - 대규모 데이터
    - 비구조화 데이터
    - 실시간 데이터
    - 기계가 생산하는 데이터
    - 소셜미디어 데이터

- 빅데이터 활용 사례 - 범죄 발생 예측 모델
- 프레드 폴을 개발
    - 범죄데이터를 학습용 데이터로 사용
    - 알고리즘 : 지각 단층에서 지진이 일어난다는 점과 일정 장소에서 범죄가 일어난다는 점에서 유사성을 찾음.
- 효과분석
    - 범죄 줄어듦.
    - 머신러닝 기술을 적용해서 예측 정확성을 보여주고 있음.

- 빅데이터 활용 사례 - 프로야구선수 가치 측정모델 만든사람
    - 효과분석
        - 적은 비용으로 높은 효과를 거두는 선수 트레이드
        - 140년 메이저리그 역사상 최초로 20연승이라는 최대 이변이자 혁신을 만들어냄.

- 빅데이터 등장배경
- 1990년 이후 인터넷 확산
    - 정형화된 데이터와 비정형화된 데이터가 무수히 발생 → 홍수 개념 등장. 
    ⇒ 오늘날의 빅데이터 개념
- 인터넷의 확산으로 변화된 환경
    - 개인화 서비스 , SNS의 확산 : 인터넷 서비스 환경이 재구성
    - 검색과 포털 위주에서 → 통신, 게임, 음악, 검색, 쇼핑등 동영상 서비스 확산.
    - 스마트폰의 보급 확산 : 유튜브를 중심 → 동영상 축적 → 제타바이트 시대 돌입.
    - internet : 서로 다른 서버간의 통신 ↔ intranet : 서로 같은 서버간의 통신

- 디지털 데이터의 단위 교재
    - 테라 10^12
    - 페타 10^15
    - 엑사 10^18
    - 제타 10^21
    - 마이크로 10^-6
    - 나노 10^-9
    - 피코 10^-12
    
- 정보 기술 변화

| PC 세대 | 스마트 시대 |
| --- | --- |
| 디지털화 , 전산화 | 지능화, 개인화, 사물 정보화 |
| PC , PC통신, 데이터 베이스  | 빅데이터, 차세대PC , 사물네트워크 |
| PC, OS | 미래전망, 상황인식, 개인화 서비스 |
| MS, IBM | 구글 ,삼성, 애플, 페이스북 , 트위터 |
| 1인 1PC | IT everwhere, 신가치 창출 |

- 데이터 규모 : 엑사 바이트 → 제타 바이트 → 제타바이트 본격화
- 데이터 유형 : 정형 데이터 → 비정형 데이터 → 사물 정보, 인지 정보
- 데이터 특성 : 구조화 → 다양성 , 복잡성, 소셜 → 현실성 , 실시간성

- 빅데이터가 차세대 이슈로 떠오르는 이유
1. 정보 기술의 주도권이 데이터로 이동
    - 모바일, 클라우드, 소셜 네트워크 서비스의 등장으로 정보기술의 주도권이 인프라와 기술에서 데이터로 이동.
    - 데이터의 폭발적인 증가에 대응, 데이터를 분석하는 방법이 정보기술의 중요한 이슈로 떠오름

1. 빅데이터는 공간 , 시간, 관계, 세상에 대한 정보
    - 사용자가 자발적으로 참여, 정보를 생성
    - SNS가 제공하는 정보는 지식정보와 함께 정서적인 공감에 바탕을 둚.
    → 감성적인 서비스가 큰 비중 차지
    - 소통방식의 변화 가져옴 → 데이터 변혁 이동 중요 요인

1. 빅데이터는 미래 경쟁력과 가치 창출의 원천
    - 빅데이터는 사회/경재적으로 성패를 좌우하는 핵심 원천이 될것.
    - 세계 각국의 정부와 기업은 빅데이터가 향후 기업의 성패를 가늠할 새로운 경제적 가치의 원천이 될것으로 기대중
    - 빅데이터 유용한 정보를 찾고, 잠재된 정보를 활용할수 있는 기업이 시장을 선도할것으로 예상

- 빅데이터의 개념과 속성
- 전통적 개념의 빅데이터
    - 방대한 양의 데이터
    - Very LargeDB, Extremely Large DB, Extreme Data, Total Data 
    등으로 불림
- 가트너의 정의 : 3V
    - 빅데이터의 속성을 volume, Variety, Velocity로 정의
    “빅데이터는 큰 용량, 빠른 속도, 다양성이 높은 정보 자산이다.
    이것으로 의사 결정 및 통찰 발견, 프로세스 최적화를 향상 시키려면 새로운 형태의 처리방법이 필요하다” 고 말함.
    - IBM : 3V + Veracity(정확성)
    - 최근 : 4V + Value(가치)

- 정확성(Veracity)
    - 데이터에 부여할수 있는 신뢰 수준을 말함.
    - 높은 데이터 품질을 유지 하는것은 빅데이터의 중요한 요구함.
        - 날씨나 경제, 고객의 미래 구매 결정같은 일부 데이터의 본질적인 불확실성은 제거 x
        - SNS와 같은 데이터는 신뢰하기 어려움 → 게시자의 편견, 소셜 노이즈, 데이터의 출처가 부정확함 → 제거
        - 미래는 예측하기 어려우며, 보이지 않는 시장의 힘 등이 빅데이터의 다양한 불확실성 형태로 나타남
- 가치(Value)
    - 빅데이터의 분석/저장에 필요한 IT 인프라 시스템을 구현하는 비용
    - 회사의 수익, 운영효율성 등 측정 가능한 도입효과 제고

- 맥킨지의 빅데이터 정의 : 참고
    - 빅데이터를 데이터베이스 규모에 초점을 맞춘 정의 제시
    - “일반적인 DBMS로 저장, 관리, 분석할수 있는 범위를 초과하는 대규모 데이터” 로 정의
    - 노무라 연구소
        - 가트너의 3V특성을 협의의 빅데이터로 분류, 인재/ 조직, 데이터 처리/축적/ 분석, 데이터(비정형, 정형)까지 포함하는 광의의 빅데이터 특성 정의

- 규모의 다양성 관점에서 본 빅데이터의 위치
    - 텍스트 위주의 데이터 → 그림, 동영상 , 음성 위주의 비정형 데이터로 이동
    - 천문, 항공 ,우주정보, 인간게놈 정보(특수분야) → 전 산업분야로 확산
    - 큰 데이터의 집합 + 비정형 데이터 = 빅데이터 (하둡, 맵리듀스)

- 스마트 기기로 생성되는 소셜 데이터와 이메일, 동영상등 비정형 데이터가 향후 10년동안 생성하는 양은 전체 데이터의 90%에 달할것으로 보임.
- 전통적 데이터와 빅데이터의 처리방식의 특징 비교

| 구분 | 전통적 데이터 | 빅데이터 |
| --- | --- | --- |
| 데이터 유형 | - 정형 데이터
- 조직 내부 데이터(고객 정보, 거래 정보 등)
- 주로 비공개 데이터 | - 비정형 데이터
- 조직 외부 데이터
- 일부 공개 데이터 |
| 테이터 특징 | - 데이터 증가량 관리 가능
- 신뢰성 높은 핵심 데이터 | - 기하 급수적으로 증가
- 쓰레기 데이터의 비중이 높다.
- 문맥 정보 등 다양한 데이터 |
| 데이터 보유 | - 정부, 기업등 대부분 조직 | - 인터넷 서비스 기업(구글..)
- 포탈(네이버)
- 이동 통신 회사(SK,LGU+)
- 디바이스 생산 회사(애플, 삼성) |

- 빅데이터의 처리 특징
- 구분/처리 특징
    - 의사결정 속도 : 빠른 의사 결정이 상대적으로 덜 요구 , 장기적, 전략적 접근 필요
    - 처리 복잡도 : 다양한 데이터 소스, 복잡한 로직처리. 대용량 데이터 처리로 복잡도가 높아 보안 처리 기술 필요
    - 데이터 규모 : 처리할 데이터 규모가 방대. 고객 정보 수집 및 분석을 장기간에 걸쳐 수행 → 처리 해야할 데이터 양 방대
    - 데이터 구조 : 비정형 제이터의 비중 높음.
    - 분석 유연성 : 처리 , 분석 유연성이 높다. 잘 정의 된 데이터 모델. 상관관계, 절차 없이 기존 데이터 처리 방법에 비해 처리 및 분석 유연성이 높은과 동시에 처리량이 낮음.
    - 처리량 : 대용량 및 복잡한 처리가 가능, 동시에 처리 할수 있는 데이터가 작음. → 실시간 처리 보장X(데이터 분석에는 부적합)

- 빅데이터 개념과 처리 과정
    - 데이터 소스 → 수집 → 저장 → 처리 → 분석 → 표현
        - 생성
            - 내부 데이터 : 데이터 베이스 , 파일 관리 시스템
            - 외부 데이터 : 인터넷으로 연결된 파일, 멀티미디어 수집
        - 수집
            - 크롤링 : 검색 엔진의 로봇을 사용한 데이터 수집
            - ETL : 소스 데이터의 추출, 전송, 변환, 적재
        - 저장
            - NoSQL데이터 베이스 : 비정형 데이터 관리
            - 스토리지 : 빅데이터 저장
            - 서버 : 초 경량 서버
        - 처리
            - 맵 리듀스 : 데이터 추출
            - 프로세싱 : 다중 업무 처리
        - 분석
            - NLP : 자연어 처리
            - 기계학습 : 데이터의 패턴 발견
            - 직렬화 : 데이터 간의 순서화
        - 표현
            - 가시화 : 데이터를 도표나 그래픽적으로 표현
            - 획득 : 데이터의 획득 및 재해석

- 빅데이터 소스 생성과 수집 단계 기술
    - 내부 데이터 : 자체적으로 보유한 내부 파일 시스템, 데이터베이스 관리 시스템, 센서 → 정형 데이터 수집
    - 외부 데이터 : 인터넷으로 연결된 외부에서 비정형 데이터 수집
    - 데이터 수집 : 룸과 프로그램으로 자동 진행. 로그 수집기, 크롤링, 센싱, RSS리더/오픈 API, ETL등을 수집 방법으로 사용
        - 로그 수집기 : 내부에 있는 웹 서버의 로그를 수집, 웹 로그, 트랜잭션 로그, 클릭 로그, DB의 로그 데이터 등을 수집
        - 크롤링 : 주로 웹 로봇, 인터넷 링크를 따라 다니며 방문한 웹 사이트의 웹 페이지라든가 소셜 데이터 등 인터넷에 공개되어 있는 데이터 수집
        - 센싱 : 각종 센서로 데이터 수집
        - RSS리더 / 오픈 API : 데이터의 생산 공유, 참여 환경인 웹 2.0을 구현
        → 프로그래밍으로 수집
        - ETL : 데이터의 추출, 변환, 적재. 다양한 소스 데이터를 취합해 데이터를 추출, 하나의 공통된 형식으로 변환 → 데이터 웨어 하우스에 적재하는 과정 지원
        
- 로그 수집기 : 여러 머신에서 발생한 로그를 한번에 분석하기 위해서 로그를 수집할수 있도록 도와주는 도구
    - 로그 수집기 요구사항
        - 모든 로그를 시간 순서대로 볼 수 있어야 한다.
        - 다수 서버 로그를 한번에 쉽게 확인해야 한다.
    - 각 머신의 사용에 따라 (대시보드, 모니터링 서버, 이벤트 서버 등) 으로 분류되어 볼 수 있어야 한다.
    - 어떤 로그들이 들어오는지 알 수 있어야 한다.
    - 로그 수집기의 종류 : logstash, fluentd, scribe, flume등
    
    - 크롤링
        - 자동화된 방법으로 웹을 탐색하는 프로그램
        - 웹 크롤러가 하는 작업을 “웹 크롤링” 혹은 “스파이더링” 이라고 한다.
        - 웹 크롤러는 시드라고 불리는 URL 리스트에서부터 시작하는데, 페이지의 모든 하이퍼링크를 URL 리스트를 갱신함.
    
    - ETL(추출, 변환, 적재 : Extract, Transform, LOAD)
        - 추출, 변환 적재는 데이터 소스로부터 데이터 웨어하우스, 데이터 마트, 데이터 통합, 데이터 이동 등 다양한 응용시스템을 위한 데이터 구축에 필요한 기술.
        - 조회 또는 분석을 목적, 적절한 포맷 or 구조로 데이터를 저장하기 위해 데이터를 변환, 최종 대상인 데이터베이스, 데이터 마트, 데이터 웨어하우스로 변환 데이터 적재.
        - ETL 솔루션 : [Integrate.io](http://Integrate.io) , Talend, Informatica Power Center, SAS Data Management, Oracle Data Integrator 5
        - 그림 참조
    
    - 데이터 Transform
        - 기본 데이터 변환 : 오류를 제거, 데이터 필드를 비우거나 데이터를 단순화 → 데이터 품질 향상
        - 데이터 정리 : 오류 제거, 소스 데이터를 대상 데이터 형식에 매핑함.
        ex_) 빈 데잍터를 숫자 0에 매핑하거나 , 데이터값 Parent를 P에 매핑하거나, child를 C에 매핑
        - 데이터 중복 제거 : 중복 레코드 식별 → 제거
        - 데이터 형식 수정 : 문자 집합, 측정 단위 및 날짜/시간 값과 같은 데이터를 일괄된 형식으로 변환 
        ex_)Kg, Pound → Pound으로 통합
    
    - 고급 데이터 변환 : 비즈니스 규칙 사용(데이터를 쉽게 분석) → 데이터 최적화
        - 파생 : 데이터에 비즈니스 규칙 적용 → 기존 값에서 새로운 값을 계산
        - 결합 : 서로 다른 데이터 소스의 동일한 데이터를 연결하는것
        - 분할 : 열 또는 데이터 속성을 대상 시스템에서 여러 열로 나눔
        ex_) 고객 이름이 조소영 이면 성과 이름을 나누듯이..(조/소영)
    - 요약 : 많은 데이터 값을더 작은 데이터 세트로 줄임 → 데이터 품질 향상
    - 암호화 : 대상 데이터베이스로 데이터를 스트리밍 하기 전에 암호화를 추가→ 데이터 보호
    
    - 데이터 Loading
        - 전체 로드 : 소스의 전체 데이터 변환 → 데이터 웨어 하우스로 이동.
        (일반적으로 전체 로드는 소스 시스템에서 데이터 웨어하우스로 데이터를 처음 로드할때 발생)
        - 증분로드 : ETL 도구가 대상 시스템과 소스 시스템 간의 델타(또는 차이)를 일정한 간격으로 로드함.(마지막 추출날짜가 저장, 이 날짜 이후에 차가된 레코드만 로드됨, 증분 로드를 구현하는 방법은 두가지.)
            - 스트리밍 증분로드: 데이터 볼륨이 작은 경우, 데이터 파인프라인을 이용해 지속적인 변경 사항을 대상 데이터 웨어 하우스로 스트리밍 할수 있음. 
            데이터 속도가 초당 수백만개의 이벤트로 증가 → 이벤트 스트림 처리 사용 → 데이터 스트림 모니터링, 처리 → 보다 신속하게 의사결정 내림
            - 배치 증분 로드 : 데이터 볼륨이 큰 경우 , 로드 데이터 변경 사항을 주기적으로 배치 단위로 수집할수 있음. 설정된 시간동안 데이터가 동기화 되면 소스 또는 대상 시스템에서 어떤 작업도 수행 X

- 빅데이터 저장기술
- 데이터에서 의미있는 정보를 추출하려면 효율적으로 저장하는 기술이 요구.
대용량, 비정형, 실시간성 속성을 수용할수 있는 저장 방식 필요.
- 대량의 데이터를 파일 형태로 저장할수 있는 기술과 비정형 데이터를 정형화된 데이터 형태로 저장하는 기술이 중요함.

| 접근 방식 | 설명 | 제품 |
| --- | --- | --- |
| - 분산파일 시스템 | - 컴퓨터 네트워크로 공유하는 여러 호스트 컴퓨터 파일에 접근할수 있는 파일 시스템 | - GFS(Google File System)
|- HDFS|
|- 아마존 S3 파일 시스템 |
| NoSQL | - 데이터 모델을 단순화→관계형 데이터 모델과 SQL을 사용하지 않는 모든 DBMS 또는 데이터 저장 장치 | - Cloudata, HBase, Cassandra |
| - 병렬 DBMS | - 다수의 마이크로 프로세서를 사용하여 여러 디스크의 질의,갱신, 입풀력 등 데이터 베이스 처리를 동시에 수행하는 데이터 베이스 시스템 | - VoltDB, Sap HANA, Vertica, Greemplum, Netezza |
| - 네트워크 구성 저장 시스템 | - 서로 다른 종류의 데이터 저장 장치를 하나의 데이터 서버에 연결,데이터 총괄관리 및 저장 | - SAN, NAS |

- Google File System(GFS)
    - 구글에 의해 개발된 분산 파일 시스템.
    - 일반 상용 하드웨어를 이용 → 대량의 서버를 연결 → 데이터 접근 효율 + 안정적, HDFS기반이 됨.
        - Master.GFS : 전체를 관리, 통제하는 중앙 서버 역할
        - Chunk Server : 물리적인 서버, 일제 입출력을 처리
        - Client : 파일 입출력을 요청하는 클라이언트 어플리케이션, 데이터의 흐름