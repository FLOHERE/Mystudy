# 데이터 분석 기술

## 01 예측 분석
- 예측분석은 연속형 속성이나 이항형 변수에 대한 모형을 만들어서, 분석하고자 하는 데이터의 결과를 예측.
	- 연속형 변수 : 주가예측, 매출, 소비에측
	- 이항형 변수 : 대출상환 여부, 질병여부
- 특징
	- 예측 분석은 입력 변수와 반응 변수의 관계에 대한 예측을 통해 예측 모델링을 수행
	- 수치형 변수의 값을 예측, 아항형 변수에 대한 예측은 분류 기법과 동일
- 주요 예측 분석 기법
	- [[의사결정 나무 분석]]
	- [[신경망 분석]]
### 01-1 이항형 변수의 예측 분석 절차
- 연속형 변수 예측 분석 절차
	- 예측변수와 반응 변수가 포함된 학습데이터를 이용 -> 의사결정나무 분석 또는 신경망 분석과 같은 기계학습 알고리즘으로 예측 모형 만듦.
	- 생성한 예측 모형에 예측 변수만 있는 자료를 입력하여 연속형 반응 변수를 산출 -> 데이터를 예측함.

## 02 연관분석
- 개요
	- 데이터 안에 존재하는 항목간의 연관 규칙(association rule)을 발견하는 과정.
	- 상품구매, 서비스 제공 등 일련의 거래나 사건들의 연관성에 규칙 생성
- 연관분석 활용
	- 월마트에서 누군가 귀저기 구입 + 맥주도 같이 삼 -> 규칙 발견
- 적용분야
	- 유통업
	- 온라인 쇼핑몰
	- 금융업
	- 의료분야

### 연관성 규칙 지표
- 지지도(support) : 규칙의 중요성에 대한 척도
	- 두 품목 X와 Y의 지지도는 전체 거래 항목중 항목 X와 항목 Y가 동시에 포함하는 거래의 비율로 지지도의 값이 클수록 자주 발생하는 거래를 의미.
	$$support = \frac  n N(XnY)$$
- 신뢰도(confidence) : 신뢰성에 대한 척도
	- 항목X가 일어난 상황에서 항목 Y가 일어날 확률(조건부 확률)
	- X를 구매한 경우 , 이중에서 얼마나 항목 Y구매로 이어지는지에 대한 의미, 신뢰도의 값이 클수록  X구매시 Y구매율이 높음을 의미.
	$$Confidence = P(Y|X) = \frac {p(XnY)} {p(X)} $$

- 향상도(lift) : 항목 X를 구매한 경우, 그 거래가 항목 Y를 포함하는 경우와  항목 Y가 임의로 구매되는 경우와의 비율. 항목 X와 Y의 구매 패턴이 독립적인지, 아니면 서로 상관 있는지를 의미.
  $$Lift=\frac{P(Y|X)}{P(Y)}=\frac{P(XnY)}{P(X) . P(Y)}$$
	- Lift >1 : 항목간 양의 상관관계에 있음
	- Lift = 1 : 항목간 독립적인 관계에 있음
	- LIft < 1 : 항목간 음의 상관관계에 있음.

### 연관분석의 절차
- 거래 데이터의 거래 항목간의 연관성 분석을 통하여 지지도, 신뢰도 , 향상도와 같은 지표들을 포함한 거래 항목들 간의 연관규칙을 생성함.
- 이후 생성된 연관 규칙들에 기반 -> 새로운 사실 발견
- 조건-반응 : "A면 B다" -> A=>B 로 표기
	- A (Antecedent) : 선행 혹은 LHS(Left hand side)  라고 함.
	- B(Consequent) : 후행 혹은 RHS(Right hand side)라고 함.

## 03 군집분석
- 개요
	- 대상들이 지니고 있는 특성의 유사성을 바탕으로 세부적인 집단들로 나누어 주는 통계 분석 기법
		- 군집 분석은 대상들을 분류하기 위한 명확한 기준이 존재하지 않거나,
		   기준이 밝혀지지 않은 상태에서 대상자들을 군집 인 집단으로 분류하는데 사용됨.
		- 자료들간의 거리(distance)또는 유사성(similarity)을 사용 -> 군집으로 나눔
- 활용
	- 소비자들의 상품구매 행동, 생활방식에 따라 소비자를 여러 집단으로 분류하여 시장 전략을 수집할때 사용
- 군집 분석 종류
	- 계층적 군집 분석
	- K-평균 군집 분석
	![[군집분석.canvas]]

### 계층적 군집 분석(hierarchical clustering method)
- 계층적 트리 모형을 이용 -> 개별 개체들을 순차적, 계층적으로 유사한 개체 또는 유사 그룹과 통합하여 군집화를 수행하는 통계 분석 기법
- 분석 방법
	- 군집 수를 정하지 않음 (n개의 군집으로부터 시작) -> 점차 군집의 개수 줄임
	- 유사성을 측정하기 위한 군집간 거리 측정 방법과 군집 연결방법 사용
	- ==군집간 거리 측정 방법==
		- ==유클리드 거리 측정법==, 유클리드 제곱거리 측정법, 체비셰프 거리 측정법, 맨해튼 거리 측정법, 민코우스키 거리 측정법 등
	- ==군집 연결 방법==
		- 최단 연결법, 최장연결법, 평균연결법, 중심 연결법, 와드 연결법

#### 군집간 거리 측정법
- 유클리드 거리 : 유클리드 거리는 두 점 사이의 거리를 계산할때 씀.
	- 피타고라스 정리와 같다.
	- 유클리드 거리 정의 가능
![[Pasted image 20231106191556.png]]
- 통계적 거리(statistical distance : SD) : 표본의 표준편차를 거리 개념에 반영
	- 표준 편차의 차이를 반영해서 거리를 측정하는 방법.
	  통계적 관점에서는 더 유의한 정보임.
	- 여기서 X는 표준편차이다.
$$SDy^2=(\frac{Xi-X}{s})^2$$

- 군집 연결 방법
	- 최단 연결법 : 군집에서 선택된 하나의 관측치와 나머지의 다른 관측치 또는 군집과의 거리 계산 -> 가장 가까운 거리에 있는 군집 또는 관측치를 연결 -> 군집 형성
	- 최장 연결법 : 군집에서 선택된 하나의 관측치와 나머지의 다른 관측치 또는 군집과의 거리를 계산, 가장 멀리 떨어진 거리에 있는 군집 또는 관측치를 연결 -> 군집 형성
	- 평균 연결법 : 군집 내의 모든 관측치들의 평균과 나머지의 다른 관측치 또는 군집과의 거리를 계산하여 최단 거리에 있는 군집 또는 관측치를 연결하여 군집을 형성하는 방법
	- 중심 연결법 : 군집 내의 모든 관측치들의 중심과 나머지의 다른 관측치 또는 군집의 중심과의 거리를 곗ㄴ하여 최단 거리에 있는 군집 또는 관측치를 연결하여 군집을 형성하는 방법
	- 와드 연결법 : 군집 내 오차 제곱합을 이용하여 군집을 형성하는 방법

### 덴드로 그램을 이용한 계층적 군집 분석
- 덴드로 그램(dendrogram)
	- 계층적 군집의 결과는 계통도 또는 덴드로 그램으로 나옴
	- 각 단계에서 관측치의 군집화를 통해 형성된 그룹과 이들의 유사성 수준을 표시하는 트리다이어 그램으로 대상들의 군집화 과정을 시각적으로 보여줌
	- 계층적인 군집 분석은 덴드로그램의 적절한 수준에서 트리를 잘라 전체 자료를 몇개 군집으로 설정

## 04 K-평균 군집 분석(K-means clustering)
- 개요
	- K-평균 군집 분석 : 지정한 군집 숫자에 따라 대상들을 군집에 할당하여 분류하는 통계분석 기법.
	- 탐색적인 차원에서 계층적 군집 분석을 통해 군집의 수를 산출하고 K- 평균 군집 분석을 수행하는 것이 바람직함.
	- 비지도 학습 모델
- 목적 : 유사한 데이터 포인트끼리 그룹핑하여 패턴을 찾아내는 것.
	- K-평균 군집 분석에서 K 클러스터의 갯수를 뜻함. 클러스터가 총 3개이면 K도 3개다.
	- means : 한 클러스터 안의 데이터 중심, 죽 centroid를 뜻함.
	- K-means Clustering 은 K개의 Centroid를 기반으로 K개의 클러스터를 만들어주는 것을 의미함.

>[!note] cluster
>"클러스터"는 비슷한 특성을 가진 데이터 포인트들의 그룹을 나타냅니다

### K 평균 군집 분석 방법
- 실행 순서
	1. 군집(Clustering) 수의 설정
		- 계층적 군집 수행 -> K의 값 결정
	2. 각 군집의 중심점(씨앗) 설정
		- 각 군집에서 중심점 또는 씨앗의 역할을 할 관측 대상을 선정
		- 군집수 만큼의 K 를 준비
		- 중심점 선정 규칙
			- 데이터 행렬에 수록되어 있는 순서대로 1번 관측대상에서 출발 -> K번 대상까지 중심점으로 사용한다
	3. 각 개체의 배치
		- 각 개체의 배치는 자기 자신과 군집의 중심점 사이의 거리가 가장 가까운 군집에 배치
	4. 개체의 재배치
		- 군집의 구성이 바뀔때 마다 중심점도 바뀜.
		- 각 관측대상과 각 군집의 중심점 사이의 거리도 달라짐
	5. 알고리즘의 종류
		- 더이상 중심점의 유의미한 변화가 없으면 종료하며, 변화의 크기가 미리 설정한 수렴 기준값보다 작게 되면 종료

## 05 텍스트 마이닝
- 텍스트 마이닝 개요
	- 텍스트 문서에서 알려지지 않은 관계 또는 패턴을 도출하여 의미있고 활용성이 높은 정보 또는 지식을 창출하는 일련의 과정
	- 자연어 처리 기술 기반
	- 데이터 마이닝과 유사/차이점
		- 유사 : 데이터를 이용해 정보 획득
		- 차이 : 텍스트 마이닝은 비정형 데이터로부터 정보 추출
	- 주요 분석 기법
		- 주제어 분석, 동시 출현 단어 분석, 토픽 모델링 감성 분석 등이 있다. 
### 텍스트 마이닝 과정
-  텍스트 데이터 획득 -> 자연어 처리, 형태소 분석 -> 구조화된 데이터로 변경 -> 정제변환 -> 텍스트 마이닝 수행 -> 발견한 규칙이나 패턴에 대한 해석 및 평가

![[텍스트 마이닝 과정.canvas]]
>[!note] 형태소 
>뜻을 가진 가장 작은 말의 단위.
>문법적 또는 관계적인 뜻만을 나타내는 단어나 단어 성분
>형태소 예) 어근, 조사 , 접사, 어미 

### 텍스트 마이닝 기법
- 주제어 분석
	-  특정 문서에서 강조하는 주제어들을 도출하는 것.
	-  그 문서에서 자주 등장하는 단어가 그 문서의 주제어 라는 전제하에 수행되는 텍스트 마이닝 기법
- 동시 출현 단어 분석
	- 동시 출현 단어 분석은 단어 간의 상관관계를 계산하여 문서 내에서 동시에 빈번하게 출현하는 단어를 분석하는 텍스트 마이닝 기법
- 토픽 모델링 
	-  비 구조화된 대량의 텍스트 자료들로 부터 의미 있는 주제인 토픽들을 추출해 주는 텍스트 마이닝 기법
- 감성 분석
	-  테스트를 분석하여 글쓴이의 의견, 감정 등을 추출해 내는 텍스트 마이닝 기법으로 , 오피니언 마이닝시 사용

### 텍스트 마이닝 주요 기술
- 통계 분석, 데이터 분석 기술, 자연어 처리 기술, 벡터 공간 모델링 기술 필요

#### 자연어 처리 기술
- 개요
	- 컴퓨터를 통해 사람의 언어를 처리하고 활용하는 분야
	- 기계가 사람의 언어 이해 -> 다양한 정보 처리에 적용 -> 빠르고 편한 정보 제공
- ==자연어 처리 단계 (4단계)==
	1. 형태소 분석 단계 : 문장을 형태소로 분리하는 과정
	2. 구문 분석 단계 : 문장의 구조와 형태를 파악하는 과정
	3. 의미 분석 단계 : 문장이 가진 의미를 파악하는 과정
	4. 활용분석 단계 : 문장의 숨은 의미나 대화의 내용을 이해하는 과정

#### 형태소 분석 기술
- 형태소 분석 : 구문, 어절 문장들을 분석하여 형태소로 분리
- 품사 태깅 : 형태소의 분저로가 품사를 표시
	- 필요성 : 생성된 형태소에 대하여 의미가 부여된 단어로 활용 -> 품사 태깅 절차 필요
	- 아버지가 가방에 들어가신다.
	  -> 아버지(보통명사) + 가(조사) + 방(보통명사) + 에(조사) + 들어가신(동사) + 다(어미)
	- R 같으 언어로 단어 추출

## 06 벡터 공간 모델링
- 문서 내 단어들을 계산 가능한 수치로 변환 시키는 것.

### ==벡터 공간 모델링 방법==
- 문서 - 단어 행렬(Document-Term Matrix, DTM)
	- 문서에 등장하는 단어들의 빈도를 행렬로 표현
	- 특정단어가 많이 등장한다 = 중요!
- 단어 - 문서 행렬(Term Document Matrix, TDM)
	- 문서를 열로, 단어를 행으로 구성
	- 문서에 나타나는 단어의 빈도수를 행렬의 값으로 표시
- 단어 빈도 - 역문서 빈도(Term Frequency-Inverse Document Frequency , TF-IDF)
	- DTM에서 행과 열의 위치가 바뀐 행렬
	- 열(세로) = 단어, 행(가로) = 문서
	- 특정 단어에 대해 서로 다른 문서와 비교 가능
	- DTM 내의 각 단어들마다 중요한 정도를 출현 빈도 대신에 단어 빈도 - 역문서 빈도라는 가중치로 설정하는 방법
	- TF-IDF 만드는 법
		1. DTM을 만든다
		2. TF-IDF 가중치를 산출하여 작성한다.
		- TF-IDF 가중치 : 단어 빈도와 역문서 빈도를 곱한 다수의 문서들을 기반으로 어떤 단어가 특정 문서 내에서 얼마나 중요한가를 나타냄
	- TF-IDF 용어
		- 단어 빈도 : 문서 내에서 특정한 단어가 출현하는 빈도
		- 문서 빈도 : 특정한 단어가 여러 문서내에서 출현하는 빈도
		- 역문서 빈도 : 문서 빈도 값의 역수
		- 단어 빈도 - 역문서 빈도 : 단어 빈도와 역문서 빈도를 곱한 수치

### 벡터 공간 모델링의 절차
1. 문서 분석을 위한 구조인 코퍼스를 구성
> 	코퍼스 : 말뭉치
2. 이틀 단어 빈도 , 단어 빈도 - 역문서 빈도를 이용하여 계산 가능한 행렬인 벡터 공간 모델로 구성
- 활용분야
	- 동시 출현 단어 분석, 토픽 모델링 , 문서 분류, 문서의 연관성 , 문서의 그룹화, 문서의 유사도 분석 등에 활용
> 	문서 분류 : 연관있는 애들끼리 유사도 뽑아내기
- 문서 분류 또는 자동 문서 분류 활용 예 : 스팸 분류기
	- 문서들의 공간 벡터 모델을 예측변수로, 문서의 분류를 반응 변수로 구성
	- 단순 베이즈, K-최근접 이웃 기법, SVM, 의사결정 나무 , 신경망 분석같은 기법 활용

>[!note] 코퍼스 
>다수의 문서로 구성, 문서들은 통계 분석을 위하여 구조화된 자료인 단어들로 구성
>코퍼스 생성 : 문서들에서 형태소 분석을 통하여 단어들을 추출하여 만듦.

## 07 주제어 분석
- 주제어 분석 개요
	- 문서에서 자주 등장하는 단어가 그 문서의 주제어 라는 전제 하에 수행
- 주제어 분석 절차
	- 텍스트 자료 -> 형태소 분석 및 데이터 정제(전처리 과정) -> 구조화된 자료 구성단어 추출 -> 빈도 분석 -> 단어들의 출현 빈도 산출 -> 단어들의 시각화 -> 주제어 분석

## 08 동시 출현 단어 분석 절차
- 동시 출현 단어 분석 개요
	- 문장 , 문단 또는 텍스트 단위에서 동시에 빈번하게 출현하는 단어를 파악
	- 단어의 상관관계를 계산 하여 단어들간의 연관성을 분석하는 텍스트 마이닝 기법
- 동시 출현 단어 분석 절차
	- 텍스트 자료 -> 형태소 분석과 정제(전처리 과정) -> 구조화된 자료 구성(코퍼스와 벡터 공간  모델링(TF-IDF) -> 연관성 분석 -> 동시 출현 네트워크 시각화를 수행 -> 단어들 간의 전체적 연관성 파악

## 09 토픽 모델링 
- 토픽 모델링 개요
	- 텍스트 자료들로부터 의미있는 주제(토픽)들을 추출하는 확률 모델 알고리즘
	- 토픽 모델링 분석 기법은 LDA(Latent Dirichilet Allocation, 잠재 디클레 할당)을 사용
		- LDA : 문서가 어떤 주제들을 다루고 있는지 예측하는 모델
		  단어들을 확률적으로 계산 -> 이 결과로 토픽 구성하는 주제어 추출
		- 문서에서 단어 추출 -> 단어를 토픽별로 분류하여 저장
		- 연속확률분포의 한 종류
- 활용 : 디지털 문헌 연구

- 토픽 모델링 절차
	- 텍스트 자료 -> 형태소 분석과 정제(전처리 과정) -> 구조화된 자료 구성(코퍼스, 벡터 공간 모델) 구성 -> 토픽 모델링 -> 다수의 토픽들을 추출
- 토픽 모델링 실행
	- 필요한 패키지
		- KoNLP(Korean Natural Language Processing) : 한글 처리 패키지
		- tm 패키지
		- topicmodels 패키지 : 토픽 모델링을 위한 기본 패키지로 일반적으로 사용되는 LDA 방식과 상관 토픽 모델링 함수들을 지원

## 10 오피니언 마이닝
- 오피니언 마이닝
- 감성 분석
- 기계학습 기반 감성 분석

- 개요
	- 텍스트 문서 내 의견이나 평가, 태도, 감성등을 추출해내는 기법
	- 문서에 나타난 의견의 양극성을 분석하는 감성 분석이 핵심
	- 데이터 마이닝 , 텍스트 마이닝과 공통점
		- 알려지지 않은 사실을 발견함.
	- 차이점 
		- 사실이 아닌 태도나 감성을 추출함
- 분석 과정
	- 텍스트 자료 -> 자연어 처리, 형태소 분석 (구조화된 데이터) -> 정제 변환 -> 감성 분석 수행(감성 사전 기반) -> 의견이나 감성에 대한 해석 및 평가 -> 지식화
![[오피니언 마이닝 분석 과정.canvas]]

### 오피니언 마이닝
- 텍스트를 분석 -> 글쓴이의 의견이나 평가, 태도, 감정등을 판별하여 의미있는 정보로 변환하고 이를 의사결정에 활용하는 과정
	- 태도를 분석, 추출

### 텍스트 마이닝
- 자연어 처리 기술에 기반하여 텍스트에서 숨겨진 관계 또는 패턴을 도출하여 유용한 정보를 추출, 가공함.
	- 사실을 분석, 추출

### 데이터 마이닝
- 대용량의 데이터로 부터 기존에 알려지지 않은 실행 가능한 정보를 추출하는 지식 발견 과정

## 11 감성 분석
- Sentiment Analysis 개요
- 주제에 대한 주관적인 인상, 감성, 태도, 개인의 의견들을 텍스트로부터 뽑아내는 분석
- 감성분석을 수행 하기 위한것
	- 감성들에 대한 긍정/부정 사전 구축
- 활용 분야
	- 영화 리뷰, 쇼핑몰 제품 구매후기

- 감성 사전
	- 긍/부 나타내는 단어 모아놓은 것.
	- 국/내외로 있음 
- 감성분석 절차
	- 텍스트 자료 -> 형태소 분석 및 데이터 정제(전처리 과정)-> 구조화된 자료 -> 빈도분석(단어들의 출현 빈도를 산출) -> 출현 단어들의 감성 점수를 산출(감성 사전 이용) -> 시각화 수행

## 12 기계학습 기반 감성 분석
- 개요
	- [[단순 베이즈 분류(Naive Bayes Classifier)]], 서포트 벡터 머신(SVM) 등을 이용하여 감성 분석 수행
	- 긍/부 에 대한 평가가 있는 문서에 문서-단어 행렬을 훈련 데이터로 활용 -> 감성 분석 모형 구축
	- 감성평가 시작(신규 자료에 대하여 찬/반 , 긍/부 , 기쁨 등등)

## 13 소셜 네트워크 분석
- 개요
	- 네트워크 그래프 : 다수의 점과 이들을 연결하는 선으로 구성됨.
	- [[노드]](node) 사이의 거리를 2차원 평면으로 표시, 그들 사이의 관계를 선(edge)로 표시
	- 통계 기법에서 제공하지 못하는 정보를 시각화 방법을 통하여 제공
- 활용분야
	- 사회 구조 분석
	- 인플루언서, 영향력 등등 인맥 정보 제공
- 분석 과정
	- 고객 데이터 -> 프로파일 추출 -> 구조화된 데이터 구성 -> 정제, 변환 -> 네트워크 분석 -> 소셜 네트워크 그래프 작성 -> 발견한 사실 , 패턴에 대한 해석 및 평가 -> 지식화
![[소셜네트워크 분석 과정.canvas]]

- 네트워크 구성 요소
	- 노드와 객체들 간의 관계를 나타내는 선으로 구성
### 네트워크 분석 지표 
- 중심성, 밀도, 노드수, 연결선 수, 네트워크의 구조 및 네트워크 객체의 영향력 등을 분석하기 위해 사용

#### 중심성(centrality)
- 네트워크에서 노드의 상대적 중요성을 나타내는 척도
	- 연결 중심성(degree centrality) : 연결이 많은 노드가 네트워크에서 중요한 노드라는 개념
	- 근접 중심성(closeness centrality) : 다른 노드들과 근접할수록 중요한 노드라는 개념
	- 중개 중심성(betweeness centrality) : 노드간 중개점에 있는 노드가 중요한 노드라는 개념
	- 고유 벡터 중심성(eigevector centrality) : 중요한 노드와 연결된 노드가 중요한 노드라는 개념
#### 밀도
- 네트워크에서 노드간의 전반적인 연결 정도 수준
	- 노드간 연결 가능한 총 수 대비 실제로 연결된 총 연결수
	- 노드 연결이 많다 = 네트워크의 밀도가 높다.
	- 밀도는 네트워크의 전체적인 구조를 분석하기 위해 사용
#### 노드수 , 엣지 수
- 네트워크의 전체적인 규모와 복잡성을 분석하기 위해 사용
	- 노드가 많은 네트워크 = 규모가 큰 네트워크
	- 엣지가 많다 = 네트워크 밀도가 높다.

## 14 소셜 네트워크 분석 기법
- 소셜 네트워크 분석 개요
- 소셜 네트워크 분석 기법 : 원-모드 소셜네트워크 + 투-모드 소셜 네트워크 모드로 구분
	- 모드 : 소셜 엔티티의 집합
		- 소셜 엔티티 : 네트워크 상에 있는 노드들

### 원-모드 소셜 네트워크
- 동일 차원의 소셜 엔티티들로 구성된 네트워크.
	- 개인 인맥 또는 회사들간의 비즈니스 관계를 나타내는 네트워크 의미
- 분석
	- 변수들간의 관계 테이블 구성 -> 근접 매트릭스로 생성 -> 네트워크 그래프로 생성
		- 관계 테이블 : 관계가 있는 객체들을 같은 행으로 구성한 테이블
		- 근접 매트릭스 : 객체들 간의 관계를 정사각형 행렬로 표시한 것.
			- 행 또는 열 이름은 네트워크 그래프에서 노드들임.

### 투-모드 소셜 네트워크
- 두개의 소셜 엔티티 집합들간의 관계 데이터로부터 생성된 네트워크
	- 차원이 다른 두개의 소셜 엔티티 집합들이 결합된 소셜 네트워크
- 분석 실행 절차
	- 시작 변수와 종점변수간의 관계 테이블 구성 -> 근접 매트릭스로 생성 -> 네트워크 그래프 작성 -> 소셜 네트워크 분석을 실시