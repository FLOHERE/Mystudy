
- HBase 구성 요소
- HMaster
    - Region 서버의 모니터링, 데이터의 일관성 보장, Region배치, 테이블의 생성, 삭제 처리 수행
    - Region 서버의 복구 및 로드 밸런싱에 관여.
    - Region 재할당.
- Zookeeper
    - 각 노드의 상태 정보를 Heartbeat 기반으로 추적하는 분산 코디네이터
    - HMaster의 위치정보 유지 및 마스터 선출 담당
    - 메타 테이블의 위치를 관리
- Region 서버
    - Region 단위로 데이터를 분산
    - Region 서버는 Root Region, Meta Region, Region이 계층적으로 구성된 트리 형태로 정보 저장
    - Region Server 마다 약 1000개의 Region을 가질수 있다.
    
    > [참고] Region은 저장해야 하는 데이터의 크기에 따라 단위가 달라진다. 
    관계형 Database와 table은 비슷한 형태이긴 하지만 , Region과 Relation은 분명히 다르다.  → 이거 이해 안되면 위에 다시 보고오자!
    > 
- Region : Store 가 있음
    - Store에는 MemStore와 storefiles 가 있다.
    - Region은 테이블을 Row Key 범위로 나눈것을 의미 한다.
    - column Family(CF)당 하나의 Store 를 갖는다.
    - Mem(emory)Store : 쓰기 캐시로 디스크에 쓰기전에 정렬화됨.CF당 하나가 존재,
    - StoreFiles(HFiles) : HDFS에 저장되는 파일이다.

- 빅데이터 저장 및 관리 기술
- Zookeeper
- 개요
    - 하둡의 분산 처리 시스템(Hadoop , Chukwa, Pig)등을 일괄적으로 관리하는 시스템
    - 클러스터에서 분산 서버들끼리 공유되는 데이터를 유지, 연산 조율에 사용됨.
    - 현재 아파치 하둡 프로젝트의 서브 프로젝트로 진행중임
    - 분산 처리 환경 : 수십대 ~수천대 서버 O, 예상하지 못한 오류 or 예외로 장애가 많이 발생함.
- Zookeeper 기능
    - 네임 서비스(클러스터 식별)를 이용한 부하 분산
    - 분산 서버들간의 동기화를 위한 락(LOCK) 기능
    - 분산 시스템 자원 코디네이션
    - 클러스터링 기능 제공
    - 장애 상황 판단 및 복구 가능
    - 장애 발생시 fail over(서비스 중단 방지) 기능 제공

- 코디네이션 기능
    - 분산 서버들간의 정보 공유, 상태점검, 동기화를 위한 LOCK처리 기능
- 코디네이션 없을때
    - 단일 장애점 발생으로 인한 시스템의 신뢰성 down
    - Race Condition 발생
        - Race Condition
            
            두개 이상의 프로세스가 공통 자원을 동시에 읽거나 쓸때 , 공용 데이터에 대한 접근이 어떤 순서에 따라 이루어졌는지에 따라 그 실행 결과가 달라지는 상황을 말함. 
            
        
        발생원인 : 분산되어 있는 어플의 실행 순서가 조율 X
        각 애플리케이션이 공유하고 있는 클러스터 자원에 무분별한 쓰기 동작으로 인해 경쟁상태(Race Condition)가 일어날 가능성 O
        
- Zookeeper 용도
    - 설정 관리 (Configuration Management)
     클러스터의 설정 정보를 최신으로 유지하기 위한 조율 시스템.
    - 클러스터 관리(Cluster Management)
    클러스터의 서버가 추가되거나 제외될 때 , 그 정보를 클러스터 내의 서버들이 공유하는데 사용됨.
    - 리더 채택(Leader Selection)
    리더는 서버가 구동될 때 자동으로 선출된다.
    - 락 , 동기화 서비스(Locking and synchronization service)
    클러스터에 쓰기 연산이 빈번할 경우 경쟁상태에 들어갈 가능성 O
    → 데이터 불일치를 발생시킴 ,  이때 클러스터 전체를 대상으로 동기화 해서 경쟁 상태에 들어가는 경우를 사전에 방지.

- Zookeeper의 구성 요소
- 클라이언트
    - 서버로 접근하여 정보를 얻는 분산 클러스트 내의 애플리케이션 (ex_kafka)
    - 클라이언트는 Zookeeper 서버들로 이루어진 앙상블에 접근하여 znode 의 데이터를 읽거나 데이터를 업데이트함.
    - znode
        
        Zookeeper 노드, 서버의 상태정보 저장
        
    - Heartbeat를 통한 클라이언트 관리
        - 클라이언트는 단일 Zookeeper 서버에 연결됨.
        - TCP 연결을 유지하여 요청을 본고 응답을 받고, 이벤트를 보고하고, Heartbeat를 보낸다.
        - TCP 연결이 끊어지면 클라이언트는 다른 서버에 연결됨.
    - 서버도 클라이언트가 연결될떄 응답을 전송, 클라이언트가 연결된 서버로부터 응답을 받지 못하면 자동으로 다른 서버로 메세지를 redirect 한다.
    - redirect
        
        메세지로 응답을 받은 후 해당 메세지를 다른 리소스 위치로 옮기는것.
        
    
- 서버
    - zookeeper 앙상블 내 노드중 하나. 클라이언트에게 응답 패킷을 전달 → 서버가 살아 있다는 것을 알림.
    - 앙상블(Ensemble Zookeeper)
        
        서버들의 그룹. 하나의 앙상블은 최소한 3개의 노드를 권장
        
    - Leader 와 Follower 로 구성
        - Leader : 모든 쓰기 요정은 리더에게 보내지고, Loader 는 Follower 에게 업데이트를 알려준다. 과반수 노드에서 변경이 저장 → 업데이트 연산 commit , 클라이언트는 업데이터가 성공했다는 응답 받음
        - Follower : 클라이언트로부터 쓰기 요청을 받아서 리더에게 전달.
    - Zookeeper 서버는 홍수로 구성해야함.
        - Zookeeper는 분산 시스템의 일부 이기때문에 멈추면 시스템이 멈출수 있음. 
        그래서 안전성을 확보하기 위해 클러스터로 구축
        - 절반 미만의 노드가 다운 되더라도 지속적으로 서비스를 제공하는 구조.
        - 자바 애플리케이션 이므로 리눅스 위에 자바가 설치 되어야 함.

- Client → Server(Follower) 로 데이터 저장을 시도할때.
    - server(Follower) → Server(Leader) → Server(Follower)로 데이터 전달함.
    - 팔로어중 과반수의 팔로어로 부터 쓸수 있다는 응답을 받으면 쓰도록 지시.
- 모든 서버에 동일 데이터가 저장된 후 클라이언트에게 응답(동기방식)

- 개요
- 빅데이터 처리 기술의 관점의 차이
    - 데이터 처리 방식
    - 데이터 구조
    - 시스템 관점

| 구분 | 기존 RDBMS | 빅데이터 |
| --- | --- | --- |
| 데이터 처리 방식 | 방대한 양의 데이터를 한번에 얼마나 빠르게 처리하는지 초점 | 저장된 방대한 양의 데이터를 사용자가 원하는 부분에 맞춰 원하는 시간에 처리하는데 초점 |
| 데이터 구조 | RDBMS의 모든 프로세스는 정형화 및 최적화된 데이터 구조에 적합한 질의를 사용하여 데이터를 다양하게 가공하고 처리 | 비 정형화된 데이터에서는 분산 클러스터 환경에서 데이터 파이프라인을 이용하여 임시 파일에 읽기와 쓰기 동작을 수행, 중간 결과값을 파일로 전달하는 방식을 사용. |
| 시스템 관점 | 고사양의 컴퓨팅 시스템을 활용 | 방대한 양의 데이터를 다루는 대부분의 기업이나 연구소 에서는 X86과 같은 저 사양의 머신 여러대를 연결하여 하나로 통합하여 사용하는 분산 컴퓨팅 시스템으로 데이터를 처리 |
- 파이프라인 : 데이터가 전달되는 경로나, 처리를 위한 기반 전체를 말함. 데이터 처리 단계의 출력이 다음 단계의 입력으로 이어지는 형태.

- 이번에 배울거 - 다양한 분선 처리 기반 서비스 플랫폼
1. Hadoop - 야후 : MapReduce 기반 분산처리 프레임 워크
2. Pig - 야후 : High level 데이터 처리 언어 프레임 워크
3. Hive - 페이스북 : 하둡 기반의 SQL 프로그램 구현 관리
4. MapR - MapR Tech : 기업에 적합한 분산 처리 통합 솔루션

- Hadoop(High Availability Distributed Object Oriented Platform)
- 하둡 역사
    - 하둡은 GFS+MapRduce를 더그 커팅이 구현한 결과물
    - NDFS(Nutch Distributed File System)를 오픈소스로 구현하여 맵 리듀스와 함께 너치에 사용
    - 아파치 최고 수준의 프로젝트

- 하둡 특징
    - 대용량 데이터를 분산 처리할수 있는 자바 기반의 오픈소스 프레임 워크
    - 여러 컴퓨터로 구성된 클러스터를 이용하여 방대한 양의 데이터를 처리하는 분산 저장 + 병렬처리 프레임 워크로 구성
    - 즉시 응답해야 하는 트랜잭션 처리 보다는 데이터를 모은 후 처리.
        
        작업을 완료해야 응답을 주는 방식으로 설계
        → 어느 정도 시간이 소요되는 방대한 양의 데이터 처리에 적합함.
        
    - HDFS(Hadoop Distributed File System) 에 데이터를 저장, MapReduce를 이용해 데이터를 처리함.
        - 분산 저장(HDFS) : 빅데이터 파일을 여러대의 서버에 분산 저장하기 위해 NameNode + DataNode로 구성.
        - 분산처리(MapReduce) : 각 서버에서 데이터를 분산 처리하는 분산 병렬처리를 위한 분석 시스템인 JobTracker와 TaskTracker로 구성

- MpaReduce 개념
    - MapReduce는 여러 노드에 태스크를분배하는 프레임 워크
    - 각 노드 프로세스 데이터는 가능한 한 해당 노드에서 데이터를 처리 → 해당 노드에 저장.(데이터 지역성)
    - MapReduce 단계
        - 맵 단계 : 하나의 큰 데이터 → 쪼개서 처리 → 흩어진 테이터를 key, value를 이용해 관련있는 데이터들로 분류
        - 리듀스 단계 : 처리된 결과를 하나로 모아서 취합 → 출력된 데이터 중에서 중복 데이터를 제거 → 원하는 데이터 추출
        - Map 과 Reduce 사이에는 shuffle 과 sort 스테이지 존재
    - 데이터 분할 : 64MB 단위로 데이터 분할 → 분할된 블록에 대해 연산
    - 마스터를 잡 트래커(Job Tracker), 슬레이브를 타스크 트래커(Task Tracker) 라고 부른다.
    - MapReduce 는 처리할 입력 데이터를 HDFS에서 읽어 들이고, 처리된 데이터는 다시 HDFS에 저장된다.

- Pig
- 개요
    - Pig : 대용량 데이터를 분석하기 위한 플랫폼, ASF에서 관리
    - MapReduce를 사용하기 위한 High level 스크립트 언어와 컴파일로 구성.
    - Pig의 언어 계층은 Pig Latin 이라 불리는 텍스트 기반의 언어로 이루어짐.
    - Java에 능숙하지 않은 프로그래머가 PigLatin을 사용하여 java로 복잡한 코드를 입력하지 않고도 MapReduce 작업을 쉽게 수행 가능
    - Pig Latin은 SQL과 유사한 언어로 SQL에 익숙하면 Aapch Pig를 쉽게 터득

- Pig의 특징
    - 풍부한 연산자 집합 : 조인, 정렬, 필터등과 같은 작업을 수행하는 연산자 제공
    - 프로그래밍 용이성 : Pig Latin은 SQL과 유사하여 프로그램 작성이 용이
        - Pig는 자바에 비해 코드 길이가 짧다.
        - Java에서 200개의 코드줄(LOC)을 입력해야 하는 작업을 Apach Pig에서 10개의 LOC만 입력하면 쉽게 수행 가능
        - 실행의 최적화 제공 : Pig의 작업은 실행을 자동으로 최적화 → 프로그래머는 코딩에만 집중.
        - 확장성 : 기존 연산자 사용 → 데이터 읽기, 처리, 쓰기 자체 기능 개발
            - 다른 프로그래밍 언어로 사용자 정의 함수 생성 , 
            Pig 스크립트에서 호출하거나 포함하는 기능 제공
    - 모든 종류의 데이터 처리 : Pig는 구조화된 데이터와 구조화 되지 않은 모든 종류의 데이터를 분석

- Pig의 데이터 표현 방식
    - field : 데이터 형에 따라 표현되는 개별 값
    - tuple : filed를 저장, 괄호로 표현
    - bag : tuple을 모은 것으로 중괄호로 표현
    - map : key 와 value 형식으로 데이터 처리
    - relation : Pig Latin으로 정의 한 데이터를 처리하는단위로 tuple의 집합, 복수의 tuple을 모은 하나의 큰 bag

- 데이터 형
    - 정수형 : int(32bit) , long(64bit)
    - 부동 소수점 형 : float형(32비트 부동 소수점), double형(64비트 부동소수점)
    - 문자열 형 : chararray , 자바의 string형 ,문자 코드는 UTF-8 만 가능
    - 바이너리 형 : byearray, 바이트형 배열
    - 연산자 : 사칙 연산자 , 비교 논리 연산자 , 논리 연산자.