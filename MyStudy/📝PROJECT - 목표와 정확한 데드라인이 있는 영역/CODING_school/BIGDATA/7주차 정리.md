
- Pig 동작 과정
- Pig Latin에서 처리를 정의하는 순서
    1. 처리대상 입력 데이터를 로드하는 방법 정의
    2. 로드한 데이터에 대한 처리 정의
    3. 처리결과를 어떻게 출력할지 정의

- 데이터의 입출력 명령 Sample
- LOAD : 하둡 파일로부터 데이터를 읽어 들이는 명령어
- FILTER : 조건과 일치하는 레코드 추출
- JOIN : 두개 이상의 relation을 결합할때 사용, 하나(또는 그룹)의 튜플을 키로 선언 → shuffling
- GROUP :  하나 이상의 관계에서 데이터를 그룹화, 동일한 키의 데이터 수집 → shuffling
- FOREACH-GENERATE : 데이터의 특정 필드를 추출 → 연산하고자 할때 사용 , → Reducing
- STORE : Pig로 처리한 F에 보관된 데이터를 저장 → Final result STORE F into output

- HIVE 개요
    - 하둡 기반의 데이터 웨어하우스(ASF에서 관리)
    - 하둡 이전 : SQL이용하여 업무 but 하둡의 MapReduce는 애플리케이션을 구현해야 데이터 처리와 분석 가능했음.
    - SQL을 익힌 엔지니어가 MarReduce 를 쉽게 이용할수 있도록 기존의 데이터 분석가를 위해 메타에서 개발한 처리 인터페이스.
    - HIVEQL이라 불리는 SQL 유사언어를 이용 → MapReduce를 실행하여 HDFS나 Hbase와 같은 데이터 저장  시스템에 저장되어 있는 대용량 데이터를 분석
    - HiveQL로 작성한 처리는 컴파일없이 바로 실행 가능, 테이블 정의 정보를 메타스토어에서 관리

- Hive 의 특징
    - Hive는 SQL 유사 인터페이스 이용 → MapReduce 실행
    - 온라인 처리에 부적합
    MapReduce잡 하나 실행 → 오버헤드 20~30초 시간 걸림 → 온라인 처리에 이용하기에 무리
    - 트랜잭션 관리 기능이 없다.
    Hive는 RDBMS와 달리 인덱스 및 트랜잭션 관리 기능이 없고, 롤백 처리가 없다.
    - 행 갱신 불가
    HDFS는 한번 기록한 데이터의 일부를 갱신할 수 없는 파일 시스템이며, UPDATE문이자 DELETE 문이 없다. 
    갱신 처리를 하려면 SLECT문으로 일단 기존 테이블의 데이터를 취득 후 , 일부를 갱신한 다음 데이터 전체를 INSERT문으로 삽입.
    
- HIVE 의 구성 요소
사용자는 ssh를 통해 HIVE 클라이언트로 접속, 하이브는 접근 포인트, 드라이버, 컴파일러, 메타스토어로 구성
    - 접근 포인트 : 사용자가 쿼리 및 기타 작업을 할때 사용하는 인터페이스
        - CL , 웹 인터페이스, Thrift 서버가 있다.
        - Thrift 서버 : Hive 쿼리문을 작성할 수 있는 API를 제공. Thrift는 언어간의 통신을 제공하는 프레임워크로 다양한 언어 지원
    - 드라이버
        - 쿼리를 입력받고, 작업을 처리하는 콘트롤러 역할 담당
        - 사용자 세션을 생성, 쿼리문 실행 및 모니터링
        - 쿼리문 실행시 생성되는 메타 데이터 저장
        - Executor : 컴파일러에 의해 생성된 타스크를 실행하고, 의존성을 가진 작업이 순차적으로 실행되도록 관리.
        - JDBC, ODBC 인터페이스 API 제공
            - JDBC(Java Database Connectivity)
                - 자바 언어에서 데이터 베이스에 접근하기 위한 APL 데이터베이스에서 자료를 업데이트 하거나 쿼리하는 방법 사용
                - DB학습시 SOL 이용 → DB에다 직접 값 넣기 or 조회
                → 일일히 할수 없음. → 프로그램한테 대신 시킴 (=JDBC)
            - ODBC(Open Database Connectivity)
                - 응용 프로그램에서 데이터에 접근하기 위한 표준 개방형 API 인터페이스 (made by MS)

- Compiler : 하이브 쿼리의 컴파일 담당
- 메타스토어
    - Hive 테이블과 파티션의 메타정보 저장
    - 메타 데이터베이스
    파일의 물리적인 위치 및 데이터에 대한 디렉터리 정보를 데이터베이스에 저장

- 참고
- HIVE : MapReduce 계산을 수행하는 SOL 형식의 스크립트를 작성하기 위한 프레임 워크
- PIG : MapReduce 프로세스용 스크립트를 만드는데 사용하는 절차적 프로그래밍 언어
- SQOOP (SQL to Hadoop): HDFS와 RDBMS간의 데이터를 가져오고 내보내는 도구

- Remote client 는 Hive 클라이언트로 SSH를 통한 접속을 함.
- Hive클라이언트 : jobClient로 동작
    - hive 서버 : Hive 쿼리를 실행할수 있는 API를 제공
    - 메타스토어 : 테이블 정의 등 메타데이터 관리 , RDBMS에 저장

- MapR
- MapR 개요
    - MapR은 사용 하둡임, Technologies에서 개발(아파치 하둡의 배포판 공급 업체)
    - HDFS를 대체하는 자체 파일 시스템 구축
    - 액티브 - 액티브 HA와 DR을 구성하는 기능 보유 : 엔터프라이즈 수준의 가용성 확보
    - HA
        
        가용성(high Availability)
        
    - DR
        
        복구 시스템(Disaster Recovery system)
        

- 단일 장애점 제거로 서비스 품질 확보
    - 단일 장애점(SPOF)인 네임노드를 제거하여 신뢰성 향상
    - CLDB(Container Location Database) 기술로 아키텍쳐 구성
        - 하둡 : NameNode는 DataNode의 블록 정보를 가지고 있고, 모든 작업의 콘트롤을 NameNode에서 진행
        - Map-R : Cluster 전체에 Name space 의 정보를 복제해서 배포. 각 볼륨마다 볼륨속 파일의 메타데이터가 있는 Name 컨테이너가 있다.
        - CLOB는 볼륨속 name 컨테이너를 찾는데 사용된다.
        - 데이터 노드에 디스크 블록 빛 복제를 관리하는 컨테이너로 구성된 파일 및 디렉토리 보유, 볼륨을 복제하는 기술
    - 대량의 노드가 구성된 클러스터 환경에서도 컨테이너 위치와 변경사항을 분산처리하여 성능 에 영향을 미치지 않는 구조
- 계층 간소화로 성능 향상
    - 하둡 파일 시스템, JVM. 리눅스 계층을 MapR 파일시스템으로 통합하여 계층을 단순화 시켜서 적시성 확보와 기존 개발 환경과 유사한 환경 제공
- 동일한 사용자 경험을 위한 MapR NFS제공
    - NFS 기능 : T 관리자, 개발자, 데이터 사이언티스트가 특별한 Hadoop 커맨드를 익히지 않고도 기존의 파일시스템과 동일한 방법으로 MapR 파일 시스템을 사용할수 있도록 지원하는 기능. 이 기능을 통하여 레거시 솔루션과도 연동이 가능하다.
- 가용성 확보 : 백업 및 HA/DR환경을 구성하여 제공
- 보안기능 제공
    - 권한, 인증 암호화, 감사 보안 기능을 제공, 클러스터에서 파일 단위까지 미세한 보안 설정으로 기업 내/외부의 플랫폼 사용자들에 대한 안전한 데이터 활용 환경 제공

- Oozie
- 개요
- 하둡 Job을 관리하기 위한 서버 기반 워크플로우 스케쥴링 시스템. ASF에서 개발 및 관리
    - Job들의 시작과 종결, 각종 분기 조건등을 지정해 자동화 하거나 스캐쥴링
    - 여러개의 MapReduce 잡을 연결하기 위해 만들어 졌으며, 잡을 손쉽게 제어 가능 → 특정 잡을 시작하거나 종료, 일시정지 할수 있음.
    - oozie 의 워크플로우에는 Control 노드와 Action노드 있음.
- 빅데이터 초기 도입 단계
특정 문제를 대상으로 한 단위 업무에 한정되므로 데이터의 소스가 제한적이거나 적용하는 mapReduce job 역시 비교적 단순한 형태.
- 확산 내지 고도화 단계
단위 프로젝트의 규모가 커지거나 넓은 영역으로 확대되어 여러개의 MapReduce job을 서로 연결해 사용

- oozie 워크플로우
- Control 노드
    - 워크 플로우의 시작과 끝(start end, fail노드)을 정의. 
    워크플로우의 실행 경로를 제어하는 메커니즘(decision, fork, join)을 제공
    - 작업의 시작과 끝을 통제 : start 노드, end 노드
    - 작업 경로 통제 : Decision 노드, Fork노드, Join노드
        - Decision 노드 : flow의 방향성을 결정
        - Fork 노드 : 하나의 Path를 여러개의 path로 분할
        - Join 노드 : 여러개의 Fork노드를 Path들을 다시 합침
- Action 노드
    - 계산 처리 작업을 실행
    - 수행 되어야 할 Job을 말함. 계산 및 처리 작업을 실행. 워크플로우가 Action 노드에 도달하면 지정된 Action을 수행
    - Hadoop file system, MapReduce, Pig, Hive, SQOOP Email cation 등 수행

- OOzie 용어
    - Action : oozie 에서 실행할 수 있는 하나의 작업 단위
    - workflow : Action들의 제어와 의존관계
    - Coordinator : Data sets과 WorkFlow 를 실행하는 스케쥴 정의
    - Bundle : 코디네이터 들의 모임
- oozie 주요 기능
    - scheduling
        - 특정시간 안에 액션 수행 or 주기적인 시간 간격 이후에 액션 수행
        - 이벤트가 발생할때 액션 수행
    - Coordinating : 이전 액션이 성공적으로 끝나면 다음 액션을 시작
    - Managing : 액션이 성공하거나 실패했을때 이메일을 발송 or 액션의 수행 시간과 역전의 단계 지정

- Greenplum
- 개요
    - 세계 최초의 오픈소스 병렬처리 MPP(Massively Parallel Processor)구조의 데이터 베이스, shared-Nothing 아키텍쳐
    - shared-Nothing
        
        네트워크 이외의 모든 자원을 분리하는 방식, 서버와 저장소를 병렬로 늘리면 성능이 선형적으로 향상됨
        
    - PastgresSQL을 기반. 대용량의 데이터 빠르게 보관, 연산, 병렬로 분석 처리.
    - PastgresSQL
        - 객체-관계형 데이터 베이스 관리 시스템(ORDBMS)임 : 확장 가능성 및 표준 준수를 강조.
        - SQL 을 기본 연산으로 지원 : MapReduce 프로그램 수행, 병렬 질의나 MapReduce 형태의 프로그램을 효율적으로 처리
    - 저장 데이터는 적용되는 연산에 따라 행 기반이나 열 기반 방식중 하나 선택
    데이터는 세그먼트 단위로 저장됨.
    - 각 처리 노드는 소프트 스위치(소프트웨어 기반의 데이터 스위치)로 연결.
    빠른 프로세서와 메모리 용량이 큰 클러스터 위에서 동작할수 있도록 분산 구조 지원

- Greenplum 구성요소
- 마스터 서버
    - DB카타로그 등 메타데이터 저장
        - 데이터베이스의 개체들에 대한 정의를 담고 있는 메타데이터 들로 구성된 데이터 베이스 내의 인스턴스, 기본 테이블, 뷰 테이블 , 동의어들, 값 범위들, 인덱스들, 사용자들, 사용자 그룹등등과 같은 데이터 베이스의 개체들 저장
        
    - 사용자 접속 관리, SQL 해석 관리, 리소스 최적화
    - 질의 요청, Parallel Dispatch 기능 수행
- 네트워크
    - 소프트 스위치 기능 제공
    - 각 세그먼트에서 병렬 파이프라인 데이터 송수신, 노드당 10Gbps 2port 나 25G 2port를 사용
    - 마스터 서버와 세그먼트 서버와의 연결
- 세그먼트 서버
    - 질의 처리
    - 사용자 데이터 저장 및 관리
    - 고급 동계 기능

- Greenplum의 특징 (1)
    - shared-nothing MPP
        - 각 노드별로 CPU, MEM Disk를 가짐. Shared-nothing
        - segment Server가 일하고 Master Server는 관리만 수행
        - 확장에 따라 선형적이고 , 고속의 쿼리 성능 보장
    - MapReduce/Hadoop
        - Pivotal Hadoop과의 고속 연동
        - Database와 Hadoop 간의 SQL 처리
        - Master Node를 통하지 않고 Segment Node에 직접 쿼리
        - Segment Node 증가에 따라 적재 성능도 증가
    - Polymorphic Storage (Row/Column)
        - 테이블 별 ROW 및 Column 단위 저장
        - Column 단위 테이블을 통하여 필요한 컬럼만 액세스 하여 I/O 를 줄일 수 있음.
    - 동적 쿼리의 최적화 및 부하 관리
        - 사용자 별 Resource Queues 관리
        - 다음 사용자 데이터 베이스 성능을 위한 MVCC기능 포함
        - Parallel Cont-Based Optmizer를 통한 쿼리 자동 최적화
- MVCC(Multi Version Concurrenct Control)
    
     동시 접근을 허용하는 데이터 베이스에서 동시성을 제어하기 위해 사용하는 방법중 하나.
    

- Greenplum특징(2)
    - 자동 Failover 기능
        - Master Node 이중화를 통한 Failover
        - segment Node Mirroring을 통한 Failover
        - Switch 이중화를 통한 failover
        - Hot Spare disk를 통한 failover
    - 백업 및 복구
        - 고속 병렬 네트워크 백업 및 복구
        - 업계 최고의 중복 제거 솔루션
        - 높은 복구 신뢰성 및 운영 효율성
        - 멀티 사이트 재해 복구
    - 병렬 처리(In-Database SAS Miner)
        - In-Database Analytics
        - SAS High-Performance Analytics Server를 통한 월등한 분석 성능 증가
    - 다양한 분석 언어 지원
        - madlib ProvotalR 등 다양한 분석통계 언어의 지원
        - In-Dataase Parallel 수행으로 대량의 데이터를 빠르게 분석
        - python, Java, Perl 등 다양한 프로시저 언어 지원

- 개요
- 빅데이터는 기존 데이터와 비교하여 의사 결정 요구가 상대적으로 빠르지 않지만, 처리할 데이터 양이 방대하여 처리 복잡도와 비정형 데이터의 비중이 높다.
    - 기존 데이터 분석 기술
    분석의 유연성은 높지만, 동시 처리량이 적은 기존 데이터 분석기법 ⇒ 빅데이터 분석 부적합.
    - 빅데이터 분석 기술
    데이터의 안전성 보다는 일부데이터에 손실이 발생해도 처리 결과에 영향을 받지 않는 업무에 적합

- 데이터 마이닝 개요
- 정의
“대용량의 데이터로 부터 기존에 알려지지 않은 실행 가능한 정보를 추출하는 지식 발견 과정”
- 데이터 마이닝 특징
    - 다면적이고 복잡적인 특성을 가지고 있는 대용량 데이터부터 사전에 파악되지 않은 유연한 정보를 생성하는 지식 발견 기법
    - 구체적으로 올바른 의사결정을 위해 데이터에서 필요한 내재 규칙이나 연관성 정보 등을 탐색하여 데이터 내의 패턴을 분석하는 작업과정
    - 데이터 마이닝 분석 기술 종류 : 분류분석, 예측 분석, 군집 분석, 연관분석
    - 구현 기술 : 인공 신경망, 의사결정 나무와 같은 기계학습 알고리즘 등