
## 빅데이터 개념과 처리 과정

- 빅데이터 처리 기술
    - 빅데이터를 여러 서버로 분산 → 각 서버에 나누어 처리 → 다시 모아서 결과를 정리 (분산, 병렬 기술 방식)
    - 구글 맵 리듀스, 하둡 맵 리듀스, 마이크로 소프트 드라이애드 등
    - 구글 맵 리듀스
        
        구글의 분산 컴퓨팅을 지원하는 소프트웨어 프레임 워크로, 함수형 프로그래밍에서 일반적으로 사용되는 맵과 리듀스 함수에 기반
        
    
- 빅데이터 실시간 처리 기술
    - 스트림 처리 기술로 강화된 스트림 컴퓨팅을 지원(InfoSphere Stream),
    분산 환경에서 스트리밍 데이터를 분석할수 있게 해주는 트위터의 스톰

- 빅데이터 처리 프로그래밍 지원 기술
    - 소잴(Sawzall) :분산 데이터를 처리하는 프로그래밍 언어
    - 하둡 Pig: 병렬처리를 하는 고성능 데이터-플로우 언어와 실행 프레임워크

 

> 카프카는 대량의 데이터를 높은 처리량과 실시간으로 취급하기 위한 제품으로 다음의 4가지를 실현함.
1. 확장성 : 여러 서버로 확장 구성할수 있기 때문에 데이터 양에 따라 시스템 확장이 가능하다.

2. 영속성 : 수신한 데이터를 ‘디스크’에 유지할수 있기 때문에 언제라도 데이터를 읽을수 있다.

3. 유연성 : “연계할수 있는 제품이 많기” 때문에 제품이나 시스템을 연결하는 허브 역할을 한다.

4. 신뢰성 : 메시지 전달 보증을 하므로 데이터를 분실을 걱정하지 않아도 된다.

- Scale-up (scale-out과 반대의 개념)
    
    스토리지, 메모리를 데이터 양에 따라 위로 늘림
    

- 인프라 기술을 포함한 빅데이터와 연계된 기술들
    - Cassandra(카산드라)
        - 분산 시스템에서 대용량 데이터를 처리, 설계된 오픈소스 데이터베이스 관리 시스템(NoSQL)
        - 페이스북에서 개발→아파치에서 관리중
    - Hadoop(하둡)
        - 분산 시스템에서 대용량 데이터 처리 분석을 지원하는 오픈소스 소프트웨어프레임 워크
        - 구글이 개발한 맵 리듀스를 오픈소스로 구현
        - 야후에서 최초로 개발 → 아파치에서 관리
        - 주요 구성요소 : HDFS( 하둡 분산 파일 시스템인), HBase(분산 칼럼 기반 데이터 베이스), 맵 리듀스(분산 컴퓨팅지원 프레임워크)
    - HBase
        - 구글의 빅데이블을 참고로 개발
        - 오픈소스 분산 비관계형 데이터 베이스
        - 파워셋에서 개발 → 아파치 소프트웨어 재단에서 관리
    - MapReduce
        - 분산 시스템에서 대용량 세트를 처리(구글에서 제안)
        - 하둡에서도 구현
    - NoSQL
        - Not-only SQL / No SQL을 의미
        - 전통적인 관계형 데이터베이스와 다르게 설계된 비관계형 데이터 베이스
        - 대표적인 NoSQL 솔루션으로 Cassandra, HBase, MongoDB 등

- 구글 맵 리듀스
    - 대규모 분산 데이터 처리를 위한 프로그램 모델. 
    소프트웨어 프레임 워크
    - 페타바이트 이상의 대용량 데이터를 범용 컴퓨터로 구성된 클러스터 환경에서 병렬처리, 함수형 프로그램으로 Map과 Reduce라는 프로그램으로 구성.
    - 클러스터
        
        수백, 수천개의 데이터를 병렬로 묶은것.
        
    - Map과 Reduce
        
        중간 단계에서 나오는 값을 묶은것.
        
    - 하둡 : 구글의 분산파일 시스템 + 맵 리듀스를 기반으로 개발
    
- 구글 빗테이블
    - HBase의 원조
    - NoSQL 계열 컬럼형 데이터 베이스
    - 각각 정렬된 키/값 매핑으로 구성, 대규모로 확장 가능한 테이블에 데이터 저장
    - 분산형 스토리지 시스템
    - 분산형 스토리지 시스템
        
        수천대의 일반서버에 걸체 페타바이트 단위의 데이터를 대규모로 확장하도록 설계, 구조화된 데이터를 관리하기 위한 분산형 스토리지 시스템
        
    - HBase API와 호환 → 별도의 변경없이 기존 HBase 애플리케이션 및 관련 도구를 사용
- bitable은 대용량 데이터를 확장하기 위해 사용됨.
분산 스토리지 시스템
- 대용량 데이터 : 페타바이트 → 수천대의 사용서버로 확장
- 구글에서 시행되는 많은 데이터가 구글bitable에 저장.
→ 데이터의 용량이 다양해서 서로 다른 요구사항을 수용함.
- 고성능 제공

- 빅데이터 처리 기술
- 맵 리듀스 : 하둡의 데이터 처리 시스템. 분산 병렬 데이터 처리 기술의 표준으로 사용됨.
    - 개요
        - 일반 범용 서버로 구성된 대규모 집합 시스템 사용
        1. 입력 데이터를 <키, 값> 형태로 데이터 분할처리
        2. 결과의 통합
        3. job 스케줄링
        4. 작업 분배
        5. 테스크 재 수행 기술이 통합된 분산 컴퓨팅 기술

- 기본 동작
    - 하둡 클러스터의 데이터 처리 → Map, Reduce의 phase로 구성
    - 맵 리듀스 작업 시작 → HDFS로 부터 파일을 가져오는 작업이 수행
    - 맵과 리듀스 사이에는 shufle과 sort라는 스테이지 존재. 각 맵 타스크는 전체 데이터 셋에 재하야 별개의 부분에 대한 작업을 수행
    → 기본적으로 하나의 HDFS block을 대상으로 수행.
    - 뱁 태스크 종료 → intermediate 데이터를 리듀스 phase를 수행할 노드로 파일을 분산 → 전송 맵 리듀스 작업이 끝나면 HDFS에 파일이 저장되면서 종료

- 하둡 구성도
- Master-slave구조를 가짐. master 노드는 한대의 노드로 구성
- MapReduce layer : MapReduce를 수행하기 위한 Layer
    - Job tracker : 사용자로부터 job요청을 받고, Task tracker에 작업 할당
    - Task tracker : job trackere로 부터 할당받은 작업을 MapReduce 하이 겹과 반환

---

- HDFS layer : 파일을 저장하기 위한 Layer
    - Name node : 작업 파일을 블록으로 나누어 Data node에 전달
    - Data node : 전달 받은 파일의 읽기/쓰기 등을 실제로 수행
    
- 빅데이터 분석기술(1/2)
    
    빅데이터 분석에 사용하는 기술은 기계학습과 마이닝 분야에서 사용됨.
    
    - 텍스트 마이닝 : 자연어 처리기술 사용, 이간의 언어로 쓰인 비정형 텍스트에서 유용한 정보를 추출, 다른 데이터의 연계성을 파악 → 분류, 군집화등 빅데이터에 숨겨진 의미있는 정보를 발견하는것.
    - 웹 마이닝 : 인터넷에서 수집한 정보를 데이터 마이닝 기법으로 분석
    - 오피니언 마이닝 :
        - 다양한 온라인뉴스와 소셜미디어 코멘트 , 사용자가 만든 콘텐츠에서 표현된 의견을 추출, 분류, 이해하고 자산화 하는 컴퓨팅 기술.
        - 텍스트 속의 감상과 감동, 여러가지 감정 상태를 분석, 사용자의 인간관계, 행동 특성등 정보를 찾아냄
        - 마케팅에서는 버즈 분석이라고도 함.
    - 리얼리티 마이닝 :
        - 휴대폰등의 기기를 사용, 인간관계와 행동 양태를 추론
        - 통화량, 통화 위치, 통화 상태, 대상, 내용을 분석 → 사용자의 인간관계, 행동 특성등 정보를 찾아냄
    - 소셜 네트워크 분석 : 수학의 그래프 이론을 바탕, 소셜, 네트워크 서비스에서 소셜 네트워크 연결 구조와 연결 강도를 분석하여 사용자의 명성 및 영향력을 측정
    - 분류 :
        - 미리 알려진 클래스들로 구분되는 훈련 데이터군을 학습 → 새로 추가되는 데이터가 속할 만한 데이터군을 찾는 지도 학습 방법
        - 가장 대표적인 방법으로 KNN(K-Nearest Neighbor)이 있음

빅데이터 분석 기술(2/2)

- 군집화(Cetoring)
    - 특성이 비슷한 데이터를 합쳐 군(Group)으로 분류하는 학습 법
    - 분류와 달리 훈련 데이터군을 이용x → 비지도 학습 방법
    - 트위터에서 주로 사진/ 카메라를 논의하는 사용자 군과과게임에 관심있는 사용자 군 등 관심사나 취미에 따라 분류
- [[기계학습]](Machine Learning)
    - 인공지능 분야에서 인간의 학습을 모델링 한 것.
    - 컴퓨터가 학습할수 있도록 하는 알고리즘과 기술을 개발 → 수신한 이메일의 스팸 여부를 판단 하도록 후련
    - 결정 트리 등 기호적 학습. 신경망이나 유전자 알고리즘 등 비기호적 학습.
    베이지안(Bayosian)이나 은닉 마코프(Hidden Maschov) 등 확률적 학습 등 다양한 기법이 있다.
- 감성 분석
    - 문장의 의미 파악 → 글의 내용에 긍정, 부정 or 좋음, 나쁨을 분류 or 만족/불만족 강도를 지수화.
    - 이 지수를 이용하여 고객의 감성 트랜드를 시계열적으로 분석
    - 고객 감성 변화에 기업의 신속한 대으 및 부정적인 의견의 확산을 방지
    
- 의미있는 데이터 분석은 보통 양에 의존
    - 소수를 대상으로한 데이터나 설문조사 → 의미X, 결과의 신뢰도 낮음
    - 의미있는 결과를 얻으려면 방대한 양의 데이터를 수집 해야함.
    - 인터넷과 컴퓨터의 발전으로 많은 양의 데이터(정형, 비정형) 수집 가능
- 인터넷과 컴퓨터의 발전으로 빅데이터 등장
    - 소셜네트워크 때문에 빅데이터 용어 등장(방대한 데이터를 만들어내기 때문)
    - 텍스트, 사진, 소리, 동영상 등과 같은 비정형 데이터 → 기존 데이터 수집 기술과 RDBMS로는 비정형 데이터 수집 불가능
    - 다양한 수집 기술과 비정형 데이터의 처리 요구됨 : 하둡 활용
    - 기존 RDBMS의 문제 보완 → 비정형 데이터 처리 어려움 → 비정형 데이터의 특성 파악 → 여러 시스템에서 파일 수집, 저장 → 분산 처리 중심
- flume : 방대한 양의 이벤트 로그 수집(cloudera)
- Chukwa : 분산 시스템의 로그 수집 및 모니터링(야후)
- Scribe : 분산 시스템 로그 수집 서버(페이스북)
- SQOOP : RDBMS 와 NoSQL 간의 데이터 연동(아파치)
- KAFKA : 분산시스템에서 메시지 전송 및 수집(linkedin)

- 하둡 개요
    
    하둡은 아파치 소프트웨어 재단의 프로젝트 아파치 라이선스로 공개
    가장 활발한 오픈 소스 프로젝트이다.
    
- 하둡 모듈
    - Hadoop Common : 다른 Hadoop 모듈을 지원하는 공통 유틸리티
    - 분산 파일 시스템(HDFS) : 애플리케이션에 대한 높은 처리량 엑세스를 제공하는 분산파일 시스템
    - YARN(Net Another Resource Negotiator) : 작업 예약 및 클러스터 리소스 관리를 위한 하둡 프레임 워크
    - MapReduce : 대용량 데이터 세트의 병렬 처리를 위한 오픈소스 프레임 워크
    - Ozone : Hadoop용 객체 저장소
- 하둡 프로젝트
    - 하둡 코아 프로젝트 : HDFS(분산 데이터 저장), MapReduce(분산 처리)
    - 하둡 서브 프로젝트 : 워크플로우 관리, 데이터 마이닝, 분석, 수집 , 직렬화 등

- 하둡 서브 프로젝트
    - Ambari : Apache Hadoop 클러스터를 프로비저닝, 관리, 모니터링 하기위한 웹 기반 도구
    - Avro : RPC(Remote Procedure Call) 및 데이터 직렬화 프레임 워크
    - Cassandra : 단일 장애 지점(Single Point of Failure)이 없는 확장 가능한 다중 마스터 데이터베이스
    - Chukwa : 대규모 분산 시스템을 관리하기 위한 데이터 수집 시스템
    - Sqoop(SQL - to - Hadoop) : RDBMS와 하둡 사이의 데이터 이동을 위한 커넥터 , 관계형 DB 와 하둡 사이에서 데이터 이관을 지원하는 툴이다. 관계형 데이터베이스의 데이터를 HDFS, 하이브, Hbase 에 임포트 하거나, 반대로 관계형 DB로 익스포트 할수 있다.
    - HBase : 대규모 테이블을 위한 구조화된 데이터 스토리지를 지원하는 확장형 분산 데이터 베이스
    - HIVE  : 데이터 요약 및 임시 쿼리를 제공하는 데이터 웨어하우스 인프라
    - Mahout : 기계 학습 및 데이터 마이닝 라이브러리, 협업 필터링, 클러스터링, 분류 기능 보유
    - Pig : 병렬 계산을 위한 높은 수준(High level) 의 데이터 흐름 언어 및 실행 프레임 워크
    - Zookeeper : 분산 애플리케이션을 위한 자원 조정 서비스 제공

| 단계별 구분 | 주요 솔루션 | 주요기능 |
| --- | --- | --- |
| 빅데이터 수집 | - 플럼
- 스쿱 | - 비정형 데이터 수집
- 관계형 DB로 부터 데이터 가져오기 |
| 빅데이터 저장, 활용 | - Hbase | - 컬럼 기반 NoSQL 데이터 베이스 |
| 빅데이터 처리 | - 하이브
- 피그
- 머하웃 | - 유사 SQL 기반 빅데이터 처리
- 스크립트 언어 기반 빅데이터 처리
- 기계학습 알고리즘 기반 빅데이터 처리 |
| - 빅데이터 관리 | - 우지
- hcatlog
- 주키퍼와 Ambari | - 빅데이터 퍼리 과정 관리
- 빅데이터의 메타 정보 관리
- 빅데이터 서브 시스템 관리 |

- 개요
    - 플럼은 Cloudera에서 개발해서 ASF로 이관한 이벤트 로그 솔루션
    - 대용량의 로그 데이터를 수집 ,집계, 이동 시키는 분산 서비스를 제공하는 솔루션
    - 스트리밍 데이터 흐름에 기반을 둔 간단하고 유연한 구조
- 플럼의 구성
    - 플럼은 소스, 채널 , 싱크로 수성
    - 소스는 웹서버, 로그 데이터 서버 등 원시 데이터 소스와 연결
    - 소스로부터 들어오는 데이터는 큐의 구조를 갖는 채널로 들어감 → 싱크 → 목표 시스템으로 전달
- 플럼의 특징
    - 신뢰도 : 장애시 로그 데이터의 유실 없이 전송 보장
    - 확장성 : 수평 확장 가능 , 분산 수집 가능한 구조
    - 효율성 : 새리운 기능 쉽게 추가하면서 고성능을 제공
    
- 구성 요소
    - Source : 외부 이벤트가 생성되어 수집되는 영역, 1개로 구성, 복수의 Channel 을 지정함.
        - Channel : Source Sink간의 버퍼 구간, 데이터 버퍼, 메모리 , 파일 , DB 저장소로 활용, 채널별로 1개의 Sink 지정
        - SInk : Sink 는 Channel로 부터 받은 데이터를 분류, 최종 목적지인 HDFS, HIVE, Elastic Search 등에 저장한다.

- Chukwa (척와)
- 개요
    - Chuckwa 는 2008년 야후에서 개발
    - 프럼과 같이 로그 데이터 수집 및 분석, 출력, 모니터링 시스템
- 특징
    - 하둡 기반으로 동작 → 반드시 하둡설치
    - 하둡 분산 파일 시스템을 그대로 수용하고 실시간 분석이 가능
- 구성요소
    - 에이전트 : 각 머신에서 실행되고, 데이터를 내보내는 역할 수행
    - 컬렉터(수집기) : 에이전트로 부터 데이터를 수신하여 저장
    - 맵 리듀스 : 데이터 구문 분석 및 보관
    - HICC(Hadoop Infrastructure Care Center) : 데이터를 표시하기 위한 웹 포털 인터페이스

- Chukwa 구성도
    - 소스 노드 , 척와 클러스터 , 저장된 레코드에 병렬 프로세싱을 수행하는 맵 리듀스로 구분함

- 척와 에이전트 : 해당 서버의 로그 파일이나 서버정보를 컬렉터로 전송
    - 로그를 수집할 대상 서버에 설치
    - 어뎁터
        - 엥전트 프로세스 안에서 실행, 데이터를 수집
        - 데이터를 청크 단위(64MB, 하둡에서 처리하는 블록의 크기)로 전송, 메타데이터가 포함
    - 에이전트는 실행될때 컬렉터를 랜덤하게 선택해서 데이터를 전송
    - 선택한 컬렉터 서버에 장애가 생기면, 설정 파일에 등록된 다른 컬렉터 서버에 데이터 전송

- 척와 컬렉트 : 에이전트로부터 전송된 데이터를 주기적으로 하둡 파일 시스템에 저장
    - 컬렉터 : 여러 대의 에이전트 서버로부터 데이터를 전송 받음
    but 하나의 파일에 저장
    - 싱크 파일 :컬렉트가 저장하는 파일 , 하둡 파일 시스템의 Sequence File 포맷으로 저장함.
    - 컬렉터는 로거 파일을 하둡 파일 시스템에 저장, 사용자 정의 Writer 지정 가능

- 데이터 프로세싱 : 아카이빙과 디먹스
    - 아카이빙 : 묶는다 (tar, jar, zip)
        - 많은 수의 데이터 싱크 파일을 소수의 아카이브 파일로 통합, 콘텐츠를 유용한 방식으로 그룹화
        - 아카이브 파일은 Hadoop 시퀀스(순서) 파일 형식, 중복 항목이 제거 되어 있음. 아카이빙은 컬렉티가 저장한 로그 파일을 이용해서 시간 순서와 동일한 그룹으로 묶는 작업을 수행
    - 디먹스 : 나눈다는 의미
        - 맵리듀스를 사용하여 데이터를 병렬로 처리
        - 로그 레코드를 파싱해서 키, 값 쌍으로 구성되는 Chukwa Record를 만든 후, 맵리듀스 작업을 거쳐서 하둡 파일 시스템에 다시 파일로 저장

- 빅데이터 수집 및 통합 기술
- Scribe(스크라이브)
- 개요
    - Facebook이 개발한 로그 서버
    - 대량의 서버로부터 실시간으로 흘러 들어오는 로그 데이터를 집약하기 위해 개발
- 특징
    - 실시간 스트리밍 로그 데이터 수집
    - 네트워크와 시스템 장애 방지를 위해 확장성과 신뢰성에 목표를 두고 잇음
    - 한대의 중앙 Scribe 서버와 여러 대의 로컬 Scribe 서버 구성
- 구성 및 동작
    - Thrift Client 와 Thrift listener 간 RPC를 통한 파일 전달
    - 중앙 Scribe 서버는 마지막 목적지의 파일에 메시지를 작성
    - 다른 층의 Scribe를 제공 → HDFS에 메시지를 전송한다.
    - Scribe는 메세지 저장을위해 Store 라는 개념 사용
        
        → HDFS에 메세지 저장
        
    - 중앙 Scribe서버가 동작되지 못하면 로컬 scribe서버 로컬 디스크에 있는 파일에 메세지를 작성, 중앙 Scribe 서버가 복구 되었을때, 다시 메세지를 전송하여 메세지 손실 방지

- 빅데이터 수집 및 통합 기술
- Thrift(스리프트)
    - 페이스북에서 개발한 소프트웨어 라이브러리면서 코드 제너레이션 등
    - RPC 구현을 위한 언어 독립적인 소프트웨어 스택, 28개 프로그램 언어를 지원(C++, CE Pytoon, JAVA, wrang Loy-)
    - RPC는 클라이언트 - 서버 구조로 작품
- Buffer : Primary store 와 secondary stores 구성
- 메세지는 먼저 Primary Store에 보내지고 Frimary Store 가 메세지를 받지 못하면 Secandury Store로 메세지를 보낸 후 Store가 사용 가능하게 되면 Secondary에서 primary로 메세지를 보낸다’

- SQOOP(SQL to Hadoop, 스쿱)
    
    스쿱은 ASF에서 개발한 정형 데이터 수집을 위한 기술, RDMS와 HDFS간의 bulk 데이터를 전송하기 위해 구현된 프로젝트 
    
    - 개요
        - SQOOP은 Hadoop 과 관계형 데이터베이스 또는 메인프레임 간의 데이터를 전송하도록 설계
        - 커넥트를 사용하여 MySQL, Oracle, MS SQL등 관계형 DB 데이터를 하둡 파일 시스템 데이터를 수집
        - 관계형 DB에서 가져온 데이터들을 하둡 맵리듀스로 변환, 변환된 데이터들을 다시 관계형 데이터 베이스로 내보낼수 있음
        - 데이터 가져오기 / 내보내기 과정을 맵 리듀스를 통해서 처리 → 병렬처리가 가능함.
    - 특징 : SQOOP은 모든 적재 과정을 자동화 하고 병렬처리 방식으로 처리
        - Bulk import 지원 : 전체 데이터 베이스 또는 테이블 HDFS로 전송
        - 데이터 전송 병렬화 : 시스템 사용률과 성능을 고려한 병렬 데이터 전송
        - Direct Input 제공 : RDB에 매핑 → Hbase 와 Hive에 직접적 import 를 제공
        - 프로그래밍 방식의 데이터인터렉션 : 자바 클래스 생성을 통한 상호 작용을 지원
- JDBC(Java Database Connectivity) : Sun Micro  시스템에서 개발
    - JDBC는 데이터 베이스에서 자료를 쿼리하거나 업데이트 하는 방법 제공, 데이터 베이스와의통신을 담당하는 인터페이스
    - DBMS간의 통신을 연결 해주는 통역자의 역할을 수행. DBMS에 종속되지 않는 API제공
    - Oracle, MS saL, MySQL 등과 같은 데이터베이스에 알맞은 JDBC 드라이버를 구현하여 제공
    - JDBC 드라이버의 구현체를 이용 → 특정 벤더의 데이터 베이스에 접근 가능

- 동작
- Import 작업
1. SSH로 작업하고자 하는 하둡 클러스터 마스터 노드에 접속
2. MySQL에 접속 → 가져올 데이터를 확인
    1. MySQL DB에서 하둡 HDFS로 가져올 SQOOP DB 및 데이터 확인
    2. `mysql > show database;
    mysql > use sqoop mysql [sqoop] > show tables
    mysql (sqoop > selcet*from sqoop_test)`
3. SQOOP 명령어로 데이터 가져오기
    1. sudo su- 명령어 실행 → root 계정으로 전환
    2. sqoop import 명령어를 사용 → 데이터를 import 시킴
    3. sqoop import …connect jdbe : mysql : // [마스터 노드 pelvate IP1 : 3306 / [데이터베이스 이름] scusername[a리스티 관리자 계정명 ] - password[클러스터 관리자 패스워트] e-table [대상 태이블]

- Drupalorg : Git 리포지토리에 호스팅된 모든 파일을 무료로 다운. 재사용, 수정 및 배포 할수 있음.
- GitHub : 분산 버전 관리들인 깃(Git)을 사용하는 프로젝트를 지원하는 웹 호스팅 서비스
- ASF : Apache Software Foundation

- KAFKA
- Kafka 개요
    - Linkedin에서 개발, 사용중인 ASF 프로젝트
    - 대량의 데이터를 높은 처리량과 실시간으로 취급하기 위한 제품. 메세지 큐와 로그 수집기 중간 영역에 있는 솔루션
    - 실시간 로그 처리에 특화
    - 이벤트를 생산자에서 소비자로 보내는 이벤트 스트리밍 플랫폼
    - 이벤트 스트리밍
        
        데이터베이스 , 센서, 모바일 장치, 클라우드 서비스 및 소프트웨어 어플리 케이션과 같은 이벤트 소스에서 실시간으로 데이터를 캡쳐하여 처리하는것.
        
    - falut_Tolerant한 아키텍쳐와 빠른 퍼포먼스로 데이터를 처리함.
- 카프카 특징
    - 확장성 : 여러 서버로 확장(Scale out) 구성할수 있기때문에 데이터 양에 따라 시스템 확장이 가능하다.
    - 영속성 : 수신한 데이터를 디스크에 유지 할수 있기때문에 언제라도 데이터를 읽을수 있다.
    - 유연성 : 연계할수 있는 제품이 많기 때문에 제품이나 시스템을 연결하는 허브 역할을 한다.
    - 신뢰성 : 메세지 전달 보증을 하므로 데이터 분실 걱정하지 않아도 된다.

- 전달 보증
- 카프카 전달 보증 기능 : 카프카는 At Most , At least Once, Exactly Once 세가지 수준으로 전달 기능 보증

| 종류 | 개요 | 재전송 유무 | 중복 삭제 유무 | 비고 |
| --- | --- | --- | --- | --- |
| At Most Once | 1회는 전달 시도 | X | X | 메세지 중복 가능성 O / 상실 O |
| At Least Once | 적어도 1회 전달 | O | X | 메세지 중복 가능성 O / 상실 X |
| Exactly Oncce | 1회만 전달 | O | O | 메세지 중복 가능성 X / 상실 X → 성능 나오기 힘듦 |

- 높은 처리량을 구현해야 했기 떄문에 초기에는 최소한 메세지 분실 방지를 위한 At least 수준으로 전달을 보증했음.

- 아파치 카프카 개요
- At Least Once
    - At Least Once 를 실현하기 위한 ACK와 오프셋 커밋이라는 개념을 도입
    - ACK
        - 브로커가 메세지를 수신했을떄 프로듀서에게 수신을 완료했다는 응답.
        ACK를 받지 못했다면 재전송
        - 정상 수신했으면 ACK 반환환
    - Offset Commit
        - 컨슈머가 브로커로부터 메세지를 받을때 어디까지 메세지를 받았는지 관리하기 위함. → 이를  이용한 전달 범위 보증의 구조를 오프셋 커밋이라고 한다.
        - 메세지를 받아 정상적으로 처리→ 오프셋 업데이트 → 잘못된 문제로 메세지를 재전송 할때도 어디서부터 재전소아면 되는지 판단.
- 메세지 수신
    - Offset Commit(정상처리)
    - 컨슈머가 수신한 메세지를 정상 처리 → 수신 완료 기록을 브로커에 남김

- Kafka 활용
    - 금융 : 실시간으로 결제 및 금융거래 처리
    - 물류 : 물류 및 자동차 산업과 같이 실시간으로 배송을 추적하고 모니ㅓ링
    - 제조 : 공장 및 풍력 단지와 같은 IOT 장치 또는 장비에서 센서 데이터를 지속적으로 캡쳐
    - 서비스 : 고객 상호 작용및 주문 수집 → 즉시 대응
    - 병원 : 환자 모니터링 , 상태 변화 예측, 응급 상황에 적시에 치료
- Kafka 구성요소
    - Producer : 메세지 생산자
    - Consumer : 메세지 소비자, Worker가 Consumer. 개별 서버 지칭
    - Consumer group
    : Consumer는 여러개의 서버를 묶어서 하나의 Consumer 그룹으로 관리 , 그룹 내의 서버들 끼리는 메세지 공유, 서버 하나가 다운되더라도 서비스가 지속 할수 있음.
    - Broker : 카프카 서버
    - Kafka Cluster : 브로커들의 묶음을 지칭
    - Zookeeper : 카프카 서버와 클러스터 상태를 관리, 클러스터 내의 Broker에 대한 데이터 분산 처리는 Zookeeper가 처리함.
    
- Kafka 클러스터
    - Topic(주제) : 데이터가 들어가는 장소
        - 카프카에 저장되는 데이터를 구분
        - 프로듀서와 컨슈머가 토픽을 기준으로 데이터를 발행, 구독
        - 하나의 토픽은 하나의 파티션으로 구성 (데이터 저장소)
    - 파티션 : Queue와 같은 First - In, First - Out형태를 유지
        - 데이터를 더 많이, 더 빨리 보내고 처리하기 위해 만들어짐.
        - 데이터 저장소 안에 분리되어진 공간이다.
        - 각 토픽 당 데이터를 분산 처리하는 단위
        - 토픽 안에 파티션을 나누어, 그 수대로 데이터를 분산 처리
        - 컨슈머가 데이터를 가져갈때 , 가장 오래된 순서부터 데이터를 가져간다.
        
        > 파티션이 없으면 1차선 도로를 달리는것과 같지만, 파티션을 늘리면 N차선 도로를 달리는 것과 같다. = 동시 처리량이 늘어남.
        > 
    - LOG
        - 1개의 메세지를 말함
        - Pratition의 한칸을 말하기도 함.
        - Key, value, time stamp로 구성됨.
    - Kafka동작
        - 발행, 구독(publish - subscribe)모델을 기반으로 동작. Producer, Consumer, Broker로 구성
            - Producer : 특정 TOPIC의 메세지를 생성한 뒤에 해당 메세지를 Broker에 전달
            - Broker : 전달받은 메세지를 Topic 번호로 분류하여 저장
            - Consumer : 해당 Topic을 구독(원하는 데이터)하는 Consumer들이 메세지를 가져가서 처리
        - Broker 는 Topic을 기준으로 메세지를 관리함.